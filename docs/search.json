[
  {
    "objectID": "ODK_geofencing.html",
    "href": "ODK_geofencing.html",
    "title": "25  ODK Geofencing",
    "section": "",
    "text": "25.1 Example : Part 1 - Creating the geofence\nIn practice it wouldn’t make a lot of sense to make a grid for the whole of the Earth at very high resolution, as you’re likely to be working on a more controlled area and the data set would get very big. So let’s take Australia as an example. You’ll find Australia within the bounds of latitude -42.0 to -10,0.01 and longitude 110 to 155.0, so the matrix need only extend to these coordinates.\nAt 0.01 (1.1km) resolution, a decomposed grid of points covering the whole of Australia is about 12 million points.\nThis is the start point for an example where we extract points that fall within a multi-polygon shape file and feed these in to ODK as the basis of a geofence. The shape files used here come from the Significant Urban Areas, Urban Centres and Localities of Australia. These are a bunch of open source shapefiles that draw polygons around major urban areas in Australia. These data are provided by the Australian Bureau of Statistics. They can be accessed here.\nThe first steps are done in R and use the libraries tidyverse and sf.\ndownload.file(\"https://www.abs.gov.au/ausstats/subscriber.nsf/log?openagent&1270055004_sua_2016_aust_shape.zip&1270.0.55.004&Data%20Cubes&1E24D1FB300696D2CA2581B1000E15A5&0&July%202016&09.10.2017&Latest\",destfile = \"data/SUA_2016_AUST.zip\")\n\nunzip(zipfile = \"data/SUA_2016_AUST.zip\",exdir = \"data/\")\nmap = read_sf(\"data/SUA_2016_AUST.shp\")  \nmap &lt;- filter(map,str_detect(map$SUA_NAME16,\"Not in any Significant Urban Area\")==FALSE)",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>ODK Geofencing</span>"
    ]
  },
  {
    "objectID": "ODK_geofencing.html#example-part-1---creating-the-geofence",
    "href": "ODK_geofencing.html#example-part-1---creating-the-geofence",
    "title": "25  ODK Geofencing",
    "section": "",
    "text": "Read the polygon shapefile and remove any problematic polygons [here there are some that aren’t in any significant urban area]\n\n\n\n\nNow create a grid of all global points at 0.1 degree resolution. The expand_grid command is useful for making a matrix this way.\n\nglobal.0.1 &lt;- expand_grid(lat = seq(-40.0,-10,0.01), lon = seq(110,150.0,0.01))\n\n\n\n\nConvert the points of the matrix to coordinates compatible with sf objects\n\npnts_sf &lt;- st_as_sf(global.0.1, coords = c('lon', 'lat'), crs = st_crs(map))\n\n\n\n\nFind the intersections of the decomposed matrix points and the template polygons\n\nThis can take a while. In our tests, 12 million points took about 10 minutes to compute\n\n\npnts_sf &lt;- st_as_sf(global.0.1, coords = c('lon', 'lat'), crs = st_crs(map))\n\n\npnts.intersection &lt;- pnts_sf %&gt;% mutate(\n                          intersection = as.integer(st_intersects(geometry, map)), \n                          area = if_else(is.na(intersection), '', map$SUA_NAME16[intersection])\n                                       )\n\n\n\n\nfilter the resulting table to include only data points that are inside polygons\nTidy this up so that lat and lon are in different fields, and provide the name of the area in the third column\n\ninside.polygons&lt;-tibble(filter(pnts.intersection,area!=\"\")) %&gt;%\n  mutate(\n    geometry = as.character(geometry),\n    geometry=str_sub(string = geometry,start = 3,end = str_length(geometry)-1),\n\n    area = as.factor(area)\n  ) %&gt;%\n  separate(geometry, c(\"lon\", \"lat\"), \", \") %&gt;%\n  mutate(\n    lon=format(round(as.numeric(lon), digits=2)) ,\n    lat=format(round(as.numeric(lat), digits=2)) ,\n    key = str_c(lon,lat,sep = \"|\")) %&gt;%\n  select(-intersection)\n\n\n\n\nFinally, export the list to a csv file, which we will use in ODK\n\nwrite_csv(inside.polygons,\"output/geofence.data.csv\")",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>ODK Geofencing</span>"
    ]
  },
  {
    "objectID": "ODK_geofencing.html#geofence-in-decomposed-csv-format",
    "href": "ODK_geofencing.html#geofence-in-decomposed-csv-format",
    "title": "25  ODK Geofencing",
    "section": "25.2 Geofence in decomposed CSV format",
    "text": "25.2 Geofence in decomposed CSV format\nThe CSV file we just created for Australia at 0.01 degree resolution had 46,000 points that fell within polygons. The table below is a sample of lines",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>ODK Geofencing</span>"
    ]
  },
  {
    "objectID": "ODK_geofencing.html#example-part-2---creating-an-xls-form-that-uses-the-geofence",
    "href": "ODK_geofencing.html#example-part-2---creating-an-xls-form-that-uses-the-geofence",
    "title": "25  ODK Geofencing",
    "section": "25.3 Example : Part 2 - Creating an XLS Form that uses the geofence",
    "text": "25.3 Example : Part 2 - Creating an XLS Form that uses the geofence\nThe XLSForm is very simple. It consists of\n\nA geopoint question, which captures the point that will be tested against the polygons. Here it is a placement-map type, but this works with GPS collected data too.\nA pair of calculations, which extract the first (Latitude) and second (Longitude) data points from the geopoint. These are rounded to the same resolution as the polygon data (here 2 decimal places, 0.01 degrees)\nAnother calculation, which concatenates the resolution-matched geopoint data in the same format found in the geofence data set\nA note, which displays the resolution-matched geopoint\nA further calculation, which grabs exactly zero or one line of matching data from the geofence data set, which is sideloaded as a csv file\nA note, which displays the name of the matching polygon",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>ODK Geofencing</span>"
    ]
  },
  {
    "objectID": "ODK_geofencing.html#example-part-3---in-action",
    "href": "ODK_geofencing.html#example-part-3---in-action",
    "title": "25  ODK Geofencing",
    "section": "25.4 Example : Part 3 - In action",
    "text": "25.4 Example : Part 3 - In action\nThis image shows a negative result, with the geopoint just outside the limits of the Forster - Tuncurry area\n\nWhilst this one shows a positive result, with the geopoint well inside the limits of Forster - Tuncurry area",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>ODK Geofencing</span>"
    ]
  },
  {
    "objectID": "ODK_geofencing.html#performance",
    "href": "ODK_geofencing.html#performance",
    "title": "25  ODK Geofencing",
    "section": "25.5 Performance",
    "text": "25.5 Performance\nThis works fast with 46000 lines (CSV was 1.6 MB) in the geopoint data. We recommend never feeding this a massive data set, but to reduce the geographical scale as you increase the resolution. Remember that XLSForms store GPS data at 6 decimal places, but you aren’t going to get this system to work at that level!\nTo give an example of why not, look at this. Forster - Tuncurry is about 45 km^2. Not a huge area. But as resolution goes up, so the number of points in the matrix expands hugely\n\n\n\n\n\n\n\n\n\nresolution degrees\nGPS decimal places\nresolution (at equator)\npoints in matrix\n\n\n\n\n0.01\n2\n1.1 km\n273\n\n\n0.001\n3\n100 m\n24,926\n\n\n0.0001\n4\n10 m\n2,463,251\n\n\n0.00001\n5\n1 m\n246,020,500\n\n\n\nRemembering that the best resolution the average GPS receiver on a phone will get is about 10 m, we benchmarked performance with 10 metre resolution or 4 decimal places. Conveniently this is also the resolution of the maps that provide the shapefiles.\nThe CSV file is now ~26 MB. Pretty big\nThe form loads on Enketo in about 8 seconds.\nThe resolution is also great\nLook at the boundary of the polygon for Forster - Tuncurry. North of the bridge is inside. South is outside. \nIf we place a marker in ODK on the bridge, it detects the point as being inside the polygon\n\nBut about 10 m south, it detects the point as being outside the polygon\n\nOn ODK Collect, the first time you use this form it will pre-load the data from the CSV, which took about 20 seconds. On subsequent uses, it takes no time at all!\n\nsystem(\"rm data/SUA*\")",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>ODK Geofencing</span>"
    ]
  },
  {
    "objectID": "ODK_Pi.html",
    "href": "ODK_Pi.html",
    "title": "26  ODK Pi - A deployable version of ODK on a Raspberry Pi",
    "section": "",
    "text": "27 ODK_Pi\nA deployable ODK Briefcase based data hub based on Raspberry Pi Raspbian.",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>ODK Pi - A deployable version of ODK on a Raspberry Pi</span>"
    ]
  },
  {
    "objectID": "ODK_Pi.html#note",
    "href": "ODK_Pi.html#note",
    "title": "26  ODK Pi - A deployable version of ODK on a Raspberry Pi",
    "section": "27.1 Note",
    "text": "27.1 Note\nThis is quite outdated and requires access to an old version of ODK Briefcase, which is no longer supported. We can’t vouch for security. Consider this an antique!",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>ODK Pi - A deployable version of ODK on a Raspberry Pi</span>"
    ]
  },
  {
    "objectID": "ODK_Pi.html#background",
    "href": "ODK_Pi.html#background",
    "title": "26  ODK Pi - A deployable version of ODK on a Raspberry Pi",
    "section": "27.2 Background",
    "text": "27.2 Background\nSome of our users are working in areas with little or no internet connection, so a portable hub for aggregating data in the field, which is able to later push data to ODK aggregate is a useful interim/backup device that can also be preconfigured to output CSVs, PDF copies of data and so on for on the ground data needs.\nThe ODK briefcase software provides all the functionality we need for this purpose. The benefits of putting briefcase on to a Raspberry Pi (RPi) are\n\nThe small size and weight of the RPi mean that you could send it in the post, carry it in your pocket and include it as a ‘just in case’ plan B measure for studies where your baggage allowance is only what you can carry.\nDedicated system means you don’t have to ‘donate’ your own laptop to study team for the duration of the work.\nThe RPi costs ~£35 and can be used with a tablet/phone/TV as display and touchscreen/keyboard/mouse as I/O devices\nRuns off pretty much any power source and has low consumption and heat output. Can be run inside a tupperware box, so good off grid, in the rainforest and so on.\nProvides full linux system including encryption/decryption, R, Python, Java etc.\nSD cards can be cloned, meaning that you can take a box of RPis and set up as many hubs as you need if the scale of project grows.\n\nThese instructions should be sufficient to set up a new installation of the Raspbian operating system, then to install any necessary packages and software (including ODK Briefcase). It will also help you to set up the system so that you can work with Android devices via the MTP protocol (which is not especially obvious) and various other tips and tricks that make all these things fit together.\nNothing in this guide is particularly difficult and not novel, but I think this is the first place where everything is listed as a single set of instructions.",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>ODK Pi - A deployable version of ODK on a Raspberry Pi</span>"
    ]
  },
  {
    "objectID": "ODK_Pi.html#equipment",
    "href": "ODK_Pi.html#equipment",
    "title": "26  ODK Pi - A deployable version of ODK on a Raspberry Pi",
    "section": "27.3 Equipment",
    "text": "27.3 Equipment\nRaspberry Pi (Tested on R Pi 3 B+)\nSDHC Micro SD card (16 GB tested) formatted to FAT / FAT32\nNoobs https://www.raspberrypi.org/downloads/noobs/",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>ODK Pi - A deployable version of ODK on a Raspberry Pi</span>"
    ]
  },
  {
    "objectID": "ODK_Pi.html#r-pi-setup",
    "href": "ODK_Pi.html#r-pi-setup",
    "title": "26  ODK Pi - A deployable version of ODK on a Raspberry Pi",
    "section": "27.4 R Pi Setup",
    "text": "27.4 R Pi Setup\n\nInstall Noobs as per instructions. Tested on Noobs Lite (Network install)\n\nCopy all files from noobs folder on to SDHC card\n\nPlug SD card in to RPi.\n\nPower on the RPi, connect to Wifi, follow steps to install Raspbian and update\n\nYou should now have a basic RPi installation of raspbian\n\nFiddle around with your wifi settings, bluetooth etc.\n\nOpen Terminal\n\n======= ### Get current date and time from internet at startup\nThe RPi doesn’t have a real time clock onboard, so I’d recommend putting on a clock board if using this in the field. Otherwise you’ll be relying on internet time. For the time being though, let’s stick with the basic board and grab internet time at startup.\nsudo nano /etc/rc.local\n\nAdd the following line to the rc.local file above where it says exit 0\n\ndate -s \"$(wget -qSO- --max-redirect=0 google.com 2&gt;&1 | grep Date: | cut -d' ' -f5-8)Z\"\n\n27.4.1 Update list of packages and remove bloatware\nI’m guessing you don’t want to play Minecraft on this RPi (though it is a great game) so let’s save about 1.5 GB of SD card space and remove bloatware that comes preinstalled on this version of Raspbian.\nsudo apt-get update  \nsudo apt-get upgrade\nsudo apt-get remove --purge wolfram-engine scratch2 libreoffice* scratch minecraft-pi sonic-pi dillo gpicview\n\nselect ‘y’ or ‘Y’ when prompted to remove these packages\nclean up leftover dependencies from removed packages\n\nsudo apt-get clean\nsudo apt-get autoremove\n\n\n27.4.2 Add required packages\nThis will add a bunch of useful things that you need\nsudo apt-get install apt-file\nsudo apt-file update\nsudo apt-get install libcurl4-openssl-dev libssl-dev libxml2 libxml2-dev libgdal-dev usbmount \n\n\n27.4.3 Install Java Development Kit (JDK)\nsudo apt-get install ca-certificates-java  \nsudo apt-get install openjdk-9-jre\n\n\n27.4.4 Get odk briefcase\ncurl --silent \"https://api.github.com/repos/opendatakit/briefcase/releases/latest\" | grep \"browser_download_url\" | sed -E 's/.*\"([^\"]+)\".*/\\1/' |xargs wget\n\n\n27.4.5 Set Jar files to open on double click\nYou probably don’t want to have to start ODK Briefcase from the command line every time you use it, so this will make jar files run by double-clicking them\n\nAdd a java.desktop file to tell OS how to handle .jar files\n\nsudo nano /usr/share/applications/java.desktop \n[[Desktop Entry]\nName=Java\nComment=Java\nGenericName=Java\nKeywords=java\nExec=/usr/bin/java -jar %f\nTerminal=false\nX-MultipleArgs=false\nType=Application\nMimeType=application/x-java-archive\nStartupNotify=true\nClose the ‘nano’ text editor by pressing CTRL & C and then press “Y” to save the new file\nAfter adding this file you should be able to find an entry called Java in the Open file with… dialog when you right click the jar file.\nSelect always open with this program and you are set to go.\nODK Briefcase should now be able to download data and export decrypted data when provided with a private key (.pem).\n\n\n27.4.6 Add support for connecting android devices\nAndroid uses the MTP protocol to connect to linux. This is no doubt safer but is a lot weirder than the old fashioned approach where it just mounted your tablet as a USB drive on your computer. Without a bit of jiggery pokery it’s hard to figure out how to find the folders. The next few steps make it much easier.\nsudo apt-get install gvfs-backends gvfs-bin gvfs-fuse gvfs-daemons  \n\nPlug in and unlock an Android device\nFind generic parent location of mount using\n\nmount | grep 'gvfsd-fuse'\n\nexample\n\n\ngvfsd-fuse on /run/user/1000/gvfs type fuse.gvfsd-fuse (rw,nosuid,nodev,relatime,user_id=1000,group_id=1000)\n\n\nthe key folder here is /run/user/1000/gvfs/ but it might be different on your system\nChange to the root directory and create a symlink to the parent directory\n\ncd ~\nln -s /run/user/1000/gvfs Android_Device\n\nOpen a file manager window and select Edit &gt; Preferences &gt; Volume Management\nUnselect “Show available options for removable media…”\n\nYou should now have a folder called “Android_Device” in the root directory. When a device is connected to the RPi, this folder should automagically get a new subfolder for the Android MTP protocol.\n\nConnect an Android device by USB cable\nUnlock the device\nSelect “Yes” to any query about using USB/MTB for transfer\nIf you navigate to the Android_Device folder you should see a folder called mtp:host… This has the device’s file system inside\nIf you don’t see that folder, press F5 to refresh\nWhen you switch devices, press F5 to update the folder.\n\nODK briefcase should now be able to pull all data from devices via the “Android_Devices” Folder.\nNavigate to it and you’ll see a uniquely named folder under which you should see the internal and SD card folders of your device. Inside one or the other will be your ODK folder. That’s the one that ODK Briefcase can pull instances from.\n\n\n27.4.7 Wireless push of instances from Android to RPi\nYou can send forms to the RPi through sftp using the excellent andFTP\n\n\n27.4.8 If you want to run a shell script by double clicking\nThis can be useful if you have downstream stuff going on, or if you want to write a script to control a batch of ODK briefcase operations from the command line interface (CLI).\n\nCreate a *.desktop file in your /usr/share/applications\nExample - do.stuff.sh\n\nnano /usr/share/applications/do.stuff.desktop\n[Desktop Entry]\nVersion=1.0  \nExec=/home/yourname/bin/do.stuff.sh  \nName=SSH Server  \nGenericName=SSH Server  \nComment=Run the do stuff script  \nEncoding=UTF-8  \nTerminal=true  \nType=Application  \nCategories=Application;Network;\nUse open with… and set as default and then script will run on double click\n\n\n27.4.9 Install R and pandoc\nUseful for analysis (R) and reporting (Pandoc) sudo apt-get install r-base r-base-dev pandoc pandoc-citeproc\n\n\n27.4.10 Change priority of WIFI networks\nThis can be useful if you want to control the precedence of networks joined over wifi.\nsudo nano /etc/wpa_supplicant/wpa_supplicant.conf\nAdd priority=2 to the wifi_B block and priority=1 to the wifi_A block in the file. Higher number is higher priority so here wifi_B will be joined by preference\nnetwork={  \n    ssid = \"wifi_A\"  \n    psk = \"passwordOfA\"  \n    priority = 1  \n}  \nnetwork={  \n   ssid = \"wifi_B\"  \n   psk = \"passwordOfB\"  \n   priority = 2  \n}",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>ODK Pi - A deployable version of ODK on a Raspberry Pi</span>"
    ]
  },
  {
    "objectID": "ODK_Pi.html#for-uk-academics-on-eduroam",
    "href": "ODK_Pi.html#for-uk-academics-on-eduroam",
    "title": "26  ODK Pi - A deployable version of ODK on a Raspberry Pi",
    "section": "27.5 For UK academics on Eduroam",
    "text": "27.5 For UK academics on Eduroam\nEduroam is a UK wide wifi provider for cross-institutional working. It can be hard to set up on RPi, but instructions here should be helpful. Below worked for me.\nsudo nano /etc/wpa_supplicant/wpa_supplicant.conf\nctrl_interface=/var/run/wpa_supplicant\nctrl_interface_group=netdev\n\ncountry=GB\n\nnetwork={\nssid=\"eduroam\"\nkey_mgmt=WPA-EAP\neap=PEAP\nphase2=\"auth=MSCHAPV2\"\nidentity=\"username@youruniversity.ac.uk\"\nanonymous_identity=\"anonymous@youruniversity.ac.uk\"\npassword=\"pwd\"\n}",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>ODK Pi - A deployable version of ODK on a Raspberry Pi</span>"
    ]
  },
  {
    "objectID": "ODK_Pi.html#hotswitching-between-networks",
    "href": "ODK_Pi.html#hotswitching-between-networks",
    "title": "26  ODK Pi - A deployable version of ODK on a Raspberry Pi",
    "section": "27.6 Hotswitching between networks",
    "text": "27.6 Hotswitching between networks\nLinux provides a nice easy way to switch between networks. A simple sh script would provide a nice clickable way to switch via a GUI, but on RPi you get the added bonus that you can connect physical switches to the pins. A push button could be used to switch between wifi networks (i.e. to move from a fully online network to an offline local wifi network provided by a hotspot. The latter is very useful if you want to use VNC software to allow using an Android tablet as a screen and interface to RPi whilst in the field.\n\nTo shift from one network to another\n\nwpa_cli select_network 0 or number of network is all you need to do.",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>ODK Pi - A deployable version of ODK on a Raspberry Pi</span>"
    ]
  },
  {
    "objectID": "ODK_Pi.html#set-up-github",
    "href": "ODK_Pi.html#set-up-github",
    "title": "26  ODK Pi - A deployable version of ODK on a Raspberry Pi",
    "section": "27.7 Set up github",
    "text": "27.7 Set up github\nGithub provides a nice way to get updated analysis scripts on to the RPi automatically. Git is built in to the Raspbian OS, so you just need to connect to GitHub to get your scripts\ngit config --global user.name \"USERNAME\"  \ngit config --global user.email \"you@youremail.com\"  \ngit config --global core.editor nano\nYou could add a git pull script at startup to ensure that all scripts are updated on startup. Alternatively you could set up a cron task.\nTo run a script after login\nsudo nano /etc/profile\nAdd the following line to the end of the file\n./home/pi/your_script_name.sh",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>ODK Pi - A deployable version of ODK on a Raspberry Pi</span>"
    ]
  },
  {
    "objectID": "ODK_Pi.html#dropbox",
    "href": "ODK_Pi.html#dropbox",
    "title": "26  ODK Pi - A deployable version of ODK on a Raspberry Pi",
    "section": "27.8 Dropbox",
    "text": "27.8 Dropbox\nDropbox is a convenient way to get data back off an RPi, though not recommended for sensitive data (at the very least you should encrypt the data).\nDropbox integration for RPi is not great, but Dropbox Uploader is an excellent script for moving stuff to and from Dropbox. These instructions are also very useful.\n\nVisit Dropbox Uploader follow the instructions in the README.MD for the most up to date instructions.",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>ODK Pi - A deployable version of ODK on a Raspberry Pi</span>"
    ]
  },
  {
    "objectID": "ODK_Pi.html#backup-your-sd-card-so-that-you-can-use-it-elsewhere-or-recover-from-mishaps",
    "href": "ODK_Pi.html#backup-your-sd-card-so-that-you-can-use-it-elsewhere-or-recover-from-mishaps",
    "title": "26  ODK Pi - A deployable version of ODK on a Raspberry Pi",
    "section": "27.9 Backup your SD card so that you can use it elsewhere or recover from mishaps",
    "text": "27.9 Backup your SD card so that you can use it elsewhere or recover from mishaps\nBEWARE that you have to use the right mount point (in the example I used /dev/disk3). If you try to write to the wrong disk when restoring the SD card, then you will probably brick your system.\nRun df to see what mounts you have. Identify which one is the disk you want to restore to.\nTo clone RPi SD Card sudo dd if=/dev/disk3 of=/Volumes/RPi_Backups/name bs=1m\nTo restore RPi SD Card sudo dd if=/Volumes/RPi_Backups/name of=/dev/disk3 bs=1m",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>ODK Pi - A deployable version of ODK on a Raspberry Pi</span>"
    ]
  },
  {
    "objectID": "ODK_Pi.html#add-a-pitft-screen",
    "href": "ODK_Pi.html#add-a-pitft-screen",
    "title": "26  ODK Pi - A deployable version of ODK on a Raspberry Pi",
    "section": "27.10 Add a PiTFT screen",
    "text": "27.10 Add a PiTFT screen\nTested using the AdaFruit Assembled 480x320 3.5” TFT+ Touchscreen (Resistive)\n\nTo install the screen\n\nShut down the RPi\nPlug the screen on to the GPIO pins of the RPi\nBoot up to Raspbian\n\n\ncd ~\nwget https://raw.githubusercontent.com/adafruit/Raspberry-Pi-Installer-Scripts/master/adafruit-pitft.sh\nchmod +x adafruit-pitft.sh\nsudo ./adafruit-pitft.sh\nThe script will attempt to install the screen automatically. When prompted to select the configuration, choose the screen you are installing, for instance &gt; 4. PiTFT 3.5” resistive touch (320x480)\nNext you need to select the screen rotation you want, for instance &gt; 1. 90 Degrees (Landscape)\nThe next two steps determine the best setting for the screen\n\nWould you like the console to appear on the PiTFT display?\n\nThis option is good if you want to use the screen as a console window. There’s no HDMI output with this config and to be honest I think it is not what most people want, so select No to this one.\n\nWould you like the HDMI display to mirror to the PiTFT display?\n\nThis option will mirror the HDMI output to the PiTFT screen, so is the better choice for most people. Select Yes to this option.\nAfter rebooting, the screen should start working, with some fairly clunky but functional touch support. (Hint : Use a pointy bit of plastic to get screen to work as a mouse)\n\n27.10.1 Set up screen to work better\n\nOpen terminal then go to Edit menu, followed by Preferences.\nChange the font to something a bit clearer like Monospace 14 Bold\n\nAdd some commands to the bin folder to allow hotswitching of the screen (saves power if you don’t need it on).\n\nMake a command for turning screen off\n\nsudo nano /usr/bin/scroff\nAdd this line to the file\nsudo sh -c 'echo \"0\" &gt; /sys/class/backlight/soc\\:backlig\nht/brightness'\npress CTRL + C and Y to save the file and close nano\n\nMake a command for turning screen on\n\nsudo nano /usr/bin/scron\nAdd this line to the file\nsudo sh -c 'echo \"1\" &gt; /sys/class/backlight/soc\\:backlig\nht/brightness'\npress CTRL + C and Y to save the file and close nano\nMake both commands executable\nsudo chmod +x /usr/bin/scroff\nsudo chmod +x /usr/bin/scron\nThen test that they work\nscroff\nshould turn the screen off and scron should turn it on again.\n\nAdd a software keyboard\nQuite hard to use on tiny screen, but could be useful in a pinch\n\nsudo apt-get install matchbox-keyboard\nsudo apt-get install libmatchbox1 -y \nsudo nano /usr/bin/toggle-matchbox-keyboard.sh\nAdd this text to the toggle-matchbox-keyboard.sh file.\n#!/bin/bash\n#This script toggle the virtual keyboard\n\nPID=`pidof matchbox-keyboard`\nif [ ! -e $PID ]; then\n  killall matchbox-keyboard\nelse\n matchbox-keyboard&\nfi\nThen close file and make executable\nsudo chmod +x /usr/bin/toggle-matchbox-keyboard.sh\nKeyboard can then be accessed through menu &gt; Accessories &gt; Keyboard",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>ODK Pi - A deployable version of ODK on a Raspberry Pi</span>"
    ]
  },
  {
    "objectID": "Docker_install_ubuntu.html",
    "href": "Docker_install_ubuntu.html",
    "title": "27  Install Docker",
    "section": "",
    "text": "27.1 Example\nIn this example, we will show how to create a minimal installation of Ubuntu, link it to a folder on your host system so that you can move files back and forth, then install OpenBUGS, a stats program that runs only on Linux or Windows.",
    "crumbs": [
      "Python, bash and other code",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Install Docker</span>"
    ]
  },
  {
    "objectID": "Docker_install_ubuntu.html#create-folders",
    "href": "Docker_install_ubuntu.html#create-folders",
    "title": "27  Install Docker",
    "section": "27.2 Create folders",
    "text": "27.2 Create folders\nFigure out what folder you want to share between your mac and the linux container\nI’m using\n/Users/icrucrob/Documents/Datasets/docker_shared\nto create a folder, start a terminal, navigate to wherever you want with cd and then use mkdir\ncd /Users/icrucrob/Documents/Datasets/mkdir\ndocker_shared",
    "crumbs": [
      "Python, bash and other code",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Install Docker</span>"
    ]
  },
  {
    "objectID": "Docker_install_ubuntu.html#create-specification-for-a-docker-container-dockerfile",
    "href": "Docker_install_ubuntu.html#create-specification-for-a-docker-container-dockerfile",
    "title": "27  Install Docker",
    "section": "27.3 Create specification for a docker container (dockerfile)",
    "text": "27.3 Create specification for a docker container (dockerfile)\ncd /Users/icrucrob/Documents/Datasets/\nnano docker_minimal\nPaste the following text in to nano, then press CTRL + x followed by y and then enter to save the dockerfile and quit nano.\nFROM ubuntu:20.04\n\n# Update package repositories and install packages\nRUN apt-get update && \\\n    apt-get clean && \\\n    rm -rf /var/lib/apt/lists/*",
    "crumbs": [
      "Python, bash and other code",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Install Docker</span>"
    ]
  },
  {
    "objectID": "Docker_install_ubuntu.html#build-the-docker-container",
    "href": "Docker_install_ubuntu.html#build-the-docker-container",
    "title": "27  Install Docker",
    "section": "27.4 Build the docker container",
    "text": "27.4 Build the docker container\ndocker buildx build -t minimal-ubuntu -f ./docker_minimal .\nIf successful, you should see something like this\n[+] Building 9.5s (7/7) FINISHED docker:desktop-linux =&gt; [internal] load .dockerignore 0.0s \n=&gt; =&gt; transferring context: 2B 0.0s =&gt; [internal] load build definition from docker_minimal 0.0s \n=&gt; =&gt; transferring dockerfile: 574B 0.0s =&gt; [internal] load metadata for docker.io/library/ubuntu:20.04 1.6s \n=&gt; [auth] library/ubuntu:pull token for registry-1.docker.io 0.0s \n=&gt; [1/2] FROM docker.io/library/ubuntu:20.04@sha256:ed4a42283d9943135ed8 3.5s \n=&gt; =&gt; resolve docker.io/library/ubuntu:20.04@sha256:ed4a42283d9943135ed8 0.0s \n=&gt; =&gt; sha256:bf40b7bc7a11b43785755d3c5f23dee03b08e988b32 2.30kB / 2.30kB 0.0s \n=&gt; =&gt; sha256:96d54c3075c9eeaed5561fd620828fd6bb5d80eca 27.51MB / 27.51MB 1.7s \n=&gt; =&gt; sha256:ed4a42283d9943135ed87d4ee34e542f7f5ad9ecf2f 1.13kB / 1.13kB 0.0s \n=&gt; =&gt; sha256:218bb51abbd1864df8be26166f847547b3851a89999ca7b 424B / 424B 0.0s \n=&gt; =&gt; extracting sha256:96d54c3075c9eeaed5561fd620828fd6bb5d80ecae7cb25f 1.7s \n=&gt; [2/2] RUN apt-get update && apt-get clean && rm -rf /var/lib/ 4.3s \n=&gt; exporting to image 0.0s \n=&gt; =&gt; exporting layers 0.0s \n=&gt; =&gt; writing image sha256:8d6b3dce84d6cf918e6ca8f2ec806ddd3aa1a018f8447 0.0s \n=&gt; =&gt; naming to docker.io/library/minimal-ubuntu 0.0s",
    "crumbs": [
      "Python, bash and other code",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Install Docker</span>"
    ]
  },
  {
    "objectID": "Docker_install_ubuntu.html#start-the-container",
    "href": "Docker_install_ubuntu.html#start-the-container",
    "title": "27  Install Docker",
    "section": "27.5 Start the container",
    "text": "27.5 Start the container\ndocker run -it -v /Users/icrucrob/Documents/Datasets/docker_shared:/chrissy minimal-ubuntu\nYou should now be able to start and stop the container using the GUI of the docker dashboard. Access the terminal through the exec tab.\nAny files you put in the shared folder will persist on both machines.",
    "crumbs": [
      "Python, bash and other code",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Install Docker</span>"
    ]
  },
  {
    "objectID": "Docker_install_ubuntu.html#install-dependencies",
    "href": "Docker_install_ubuntu.html#install-dependencies",
    "title": "27  Install Docker",
    "section": "27.6 Install dependencies",
    "text": "27.6 Install dependencies\nThis should be done in the docker container’s terminal\napt update\napt upgrade\napt install curl\napt install cmake\napt install gcc\napt install gcc-multilib\napt install man-db\napt install gawk",
    "crumbs": [
      "Python, bash and other code",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Install Docker</span>"
    ]
  },
  {
    "objectID": "Docker_install_ubuntu.html#get-the-openbugs-source",
    "href": "Docker_install_ubuntu.html#get-the-openbugs-source",
    "title": "27  Install Docker",
    "section": "27.7 Get the OpenBUGS source",
    "text": "27.7 Get the OpenBUGS source\ncurl https://www.mrc-bsu.cam.ac.uk/wp-content/uploads/2018/04/OpenBUGS-3.2.3.tar.gz –output OpenBUGS-3.2.3.tar.gz",
    "crumbs": [
      "Python, bash and other code",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Install Docker</span>"
    ]
  },
  {
    "objectID": "Docker_install_ubuntu.html#install-openbugs",
    "href": "Docker_install_ubuntu.html#install-openbugs",
    "title": "27  Install Docker",
    "section": "27.8 Install OpenBUGS",
    "text": "27.8 Install OpenBUGS\ntar -xvzf OpenBUGS-3.2.3.tar.gz\ncd OpenBUGS-3.2.3\n./configure\nmake\nmake install\nunminimize",
    "crumbs": [
      "Python, bash and other code",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Install Docker</span>"
    ]
  },
  {
    "objectID": "Docker_install_ubuntu.html#check-the-installation",
    "href": "Docker_install_ubuntu.html#check-the-installation",
    "title": "27  Install Docker",
    "section": "27.9 Check the installation",
    "text": "27.9 Check the installation\nOpenBUGS\nIf it is working, you should see the OpenBUGS prompt\nOpenBUGS version 3.2.3 rev 1012\ntype 'modelQuit()' to quit\nOpenBUGS&gt;",
    "crumbs": [
      "Python, bash and other code",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Install Docker</span>"
    ]
  },
  {
    "objectID": "Join_photos_randomly.html",
    "href": "Join_photos_randomly.html",
    "title": "28  Join Photos side-by-side with tracked random arrangement",
    "section": "",
    "text": "28.1 Background\nThis python script was written to support a team who needed paired photos to be shown side by side, but with randomisation of which photo went on the left and which on the right in each pair.",
    "crumbs": [
      "Python, bash and other code",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Join Photos side-by-side with tracked random arrangement</span>"
    ]
  },
  {
    "objectID": "Join_photos_randomly.html#inputs",
    "href": "Join_photos_randomly.html#inputs",
    "title": "28  Join Photos side-by-side with tracked random arrangement",
    "section": "28.2 Inputs",
    "text": "28.2 Inputs\nThe inputs are (1) a folder in of image files with unique names\n\nlist.files(\"data/join_photos_randomly/in/\")\n\n[1] \"A.jpg\" \"B.jpg\" \"C.jpg\" \"D.jpg\" \"E.jpg\" \"F.jpg\"\n\n\n\n\n\n\n\n\nand (2) a file photo_pairs_in.csv which lists the pairs and provides a subject identifier.\n\nlibrary(tidyverse)\ndf&lt;-read_csv(\"data/join_photos_randomly/photo_pairs_in.csv\")\n(df)\n\n# A tibble: 3 × 3\n  subject prewash postwash\n    &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;   \n1       1 A.jpg   B.jpg   \n2       2 C.jpg   D.jpg   \n3       3 E.jpg   F.jpg",
    "crumbs": [
      "Python, bash and other code",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Join Photos side-by-side with tracked random arrangement</span>"
    ]
  },
  {
    "objectID": "Join_photos_randomly.html#python-script",
    "href": "Join_photos_randomly.html#python-script",
    "title": "28  Join Photos side-by-side with tracked random arrangement",
    "section": "28.3 Python script",
    "text": "28.3 Python script\nCreate a new text document (photo_joiner.py) and save to the same folder as the input csv file.\n##################################################################\n# PHOTO JOINER WITH RANDOMISER\n# This script takes a list of paired photos and joins them\n# Joining is side by side\n# and randomised\n# The script creates a new joined image file in the out folder\n# and also records which image was on the left, which on the right\n#\n# Core code is copyright Chrissy h Roberts\n# Chrissy.Roberts@LSHTM.ac.uk\n# CC-BY 4.0 (https://creativecommons.org/licenses/by/4.0/)\n#\n# Imported libraries are used according to their individual licenses\n# Pillow library used under License: Historical Permission Notice and Disclaimer (HPND) (HPND)\n# Pillow written by Jeffrey A. Clark (Alex)\n##################################################################\n# Import libraries needed for this analysis\n\nimport os\nimport random\nimport csv\nfrom PIL import Image\n\n\n# Input directory containing your photo pairs\ninput_dir = \"in\"\n\n# Output directory for saving the joined images\noutput_dir = \"out\"\n\n# Input CSV file containing subject and photo filenames\ninput_csv_file = \"photo_pairs_in.csv\"\n\n# Output CSV file for logging\noutput_csv_file = \"photo_pairs_out.csv\"\n\n# Set the random seed for reproducible randomness\nrandom_seed = 42  # You can change this seed to any integer you prefer\nrandom.seed(random_seed)\n\n# Create a dictionary to map subjects to photo pairs\nsubject_to_photos = {}\n\n# Read the input CSV file and populate the dictionary\nwith open(input_csv_file, \"r\") as csv_file:\n    csv_reader = csv.DictReader(csv_file)\n    for row in csv_reader:\n        subject = row[\"subject\"]\n        prewash_photo = row[\"prewash\"]\n        postwash_photo = row[\"postwash\"]\n        subject_to_photos[subject] = (prewash_photo, postwash_photo)\n\n# Create a new CSV file for logging with \"left\" and \"right\" columns\ncsv_file = open(output_csv_file, \"w\", newline=\"\")\ncsv_writer = csv.writer(csv_file)\ncsv_writer.writerow([\"subject\", \"left\", \"right\"])\n\n# Process and rename the photos for each subject\nfor subject, (prewash_photo, postwash_photo) in subject_to_photos.items():\n    # Randomly assign which photo is on the left and which is on the right\n    if random.choice([True, False]):\n        left_photo, right_photo = prewash_photo, postwash_photo\n    else:\n        left_photo, right_photo = postwash_photo, prewash_photo\n\n    # Load the left and right photos using PIL\n    left_image = Image.open(os.path.join(input_dir, left_photo))\n    right_image = Image.open(os.path.join(input_dir, right_photo))\n\n    # Concatenate the photos horizontally\n    joined_image = Image.new(\"RGB\", (left_image.width + right_image.width, left_image.height))\n    joined_image.paste(left_image, (0, 0))\n    joined_image.paste(right_image, (left_image.width, 0))\n\n    # Save the joined photo in the output directory\n    joined_photo_filename = f\"{subject}.jpg\"\n    joined_image.save(os.path.join(output_dir, joined_photo_filename))\n\n    # Write the new mapping to the output CSV file\n    csv_writer.writerow([subject, left_photo, right_photo])\n\n    print(f\"Processed subject {subject}: {left_photo} + {right_photo} =&gt; {joined_photo_filename}\")\n\n# Close the output CSV file\ncsv_file.close()\nTo run this script, open a terminal, change directory to the folder and type python3 photo_joiner.py",
    "crumbs": [
      "Python, bash and other code",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Join Photos side-by-side with tracked random arrangement</span>"
    ]
  },
  {
    "objectID": "Join_photos_randomly.html#outputs",
    "href": "Join_photos_randomly.html#outputs",
    "title": "28  Join Photos side-by-side with tracked random arrangement",
    "section": "28.4 Outputs",
    "text": "28.4 Outputs\nThe outputs are saved in a folder (out) in the form of the joined photos\n\n\n\nNote that no correction is made for the sizes, so some clipping will occur if the larger photo is on the right. We recommend using photos that have a consistent size.\nThe data on which photos were on the left or right is stored in the photo_pairs_out.csv file.\n\nlibrary(tidyverse)\ndf&lt;-read_csv(\"data/join_photos_randomly/photo_pairs_out.csv\")\n(df)\n\n# A tibble: 3 × 3\n  subject left  right\n    &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n1       1 A.jpg B.jpg\n2       2 C.jpg D.jpg\n3       3 F.jpg E.jpg",
    "crumbs": [
      "Python, bash and other code",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Join Photos side-by-side with tracked random arrangement</span>"
    ]
  },
  {
    "objectID": "Akaike_Information_Criterion.html",
    "href": "Akaike_Information_Criterion.html",
    "title": "29  Akaike information criterion",
    "section": "",
    "text": "29.1 Example\nYou want to know whether drinking sugar-sweetened beverages influences body weight. You have collected secondary data from a national health survey that contains observations on sugar-sweetened beverage consumption, age, sex, and BMI (body mass index).\nTo find out which of these variables are important for predicting the relationship between sugar-sweetened beverage consumption and body weight, you create several possible models and compare them using AIC.",
    "crumbs": [
      "Cribsheet [Other people's work]",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Akaike information criterion</span>"
    ]
  },
  {
    "objectID": "Akaike_Information_Criterion.html#when-to-use-aic",
    "href": "Akaike_Information_Criterion.html#when-to-use-aic",
    "title": "29  Akaike information criterion",
    "section": "29.2 When to use AIC",
    "text": "29.2 When to use AIC\nIn statistics, AIC is most often used for model selection. By calculating and comparing the AIC scores of several possible models, you can choose the one that is the best fit for the data.\nWhen testing a hypothesis, you might gather data on variables that you aren’t certain about, especially if you are exploring a new idea. You want to know which of the independent variables you have measured explain the variation in your dependent variable.\nA good way to find out is to create a set of models, each containing a different combination of the independent variables you have measured. These combinations should be based on:\nYour knowledge of the study system – avoid using parameters that are not logically connected, since you can find spurious correlations between almost anything!\nYour experimental design – for example, if you have split two treatments up among test subjects, then there is probably no reason to test for an interaction between the two treatments.\nOnce you’ve created several possible models, you can use AIC to compare them. Lower AIC scores are better, and AIC penalizes models that use more parameters. So if two models explain the same amount of variation, the one with fewer parameters will have a lower AIC score and will be the better-fit model.",
    "crumbs": [
      "Cribsheet [Other people's work]",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Akaike information criterion</span>"
    ]
  },
  {
    "objectID": "Akaike_Information_Criterion.html#model-selection-example",
    "href": "Akaike_Information_Criterion.html#model-selection-example",
    "title": "29  Akaike information criterion",
    "section": "29.3 Model selection example",
    "text": "29.3 Model selection example\nIn a study of how hours spent studying and test format (multiple choice vs. written answers) affect test scores, you create two models:\nFinal test score in response to hours spent studying\nFinal test score in response to hours spent studying + test format\nYou find an r2 of 0.45 with a p-value less than 0.05 for model 1, and an r2 of 0.46 with a p-value less than 0.05 for model 2. Model 2 fits the data slightly better – but was it worth it to add another parameter just to get this small increase in model fit?\nYou run an AIC test to find out, which shows that model 1 has the lower AIC score because it requires less information to predict with almost the exact same level of precision. Another way to think of this is that the increased precision in model 2 could have happened by chance.\nFrom the AIC test, you decide that model 1 is the best model for your study.",
    "crumbs": [
      "Cribsheet [Other people's work]",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Akaike information criterion</span>"
    ]
  },
  {
    "objectID": "Akaike_Information_Criterion.html#how-to-compare-models-using-aic",
    "href": "Akaike_Information_Criterion.html#how-to-compare-models-using-aic",
    "title": "29  Akaike information criterion",
    "section": "29.4 How to compare models using AIC",
    "text": "29.4 How to compare models using AIC\nAIC determines the relative information value of the model using the maximum likelihood estimate and the number of parameters (independent variables) in the model. The formula for AIC is:\nThe mathematical formula for calculating Akaike information criterion.\nK is the number of independent variables used and L is the log-likelihood estimate (a.k.a. the likelihood that the model could have produced your observed y-values). The default K is always 2, so if your model uses one independent variable your K will be 3, if it uses two independent variables your K will be 4, and so on.\nTo compare models using AIC, you need to calculate the AIC of each model. If a model is more than 2 AIC units lower than another, then it is considered significantly better than that model.\nYou can easily calculate AIC by hand if you have the log-likelihood of your model, but calculating log-likelihood is complicated! Most statistical software will include a function for calculating AIC. We will use R to run our AIC analysis.",
    "crumbs": [
      "Cribsheet [Other people's work]",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Akaike information criterion</span>"
    ]
  },
  {
    "objectID": "Akaike_Information_Criterion.html#aic-in-r",
    "href": "Akaike_Information_Criterion.html#aic-in-r",
    "title": "29  Akaike information criterion",
    "section": "29.5 AIC in R",
    "text": "29.5 AIC in R\nTo compare several models, you can first create the full set of models you want to compare and then run aictab() on the set.\nFor the sugar-sweetened beverage data, we’ll create a set of models that include the three predictor variables (age, sex, and beverage consumption) in various combinations.\nLoad the dataset\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(knitr)\nbmi.data &lt;- read_csv(\"data/bmi.data.csv\")\n\nRows: 500 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): sex\ndbl (3): age, consumption, bmi\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nCreate the models\nFirst, we can test how each variable performs separately.\n\nage.mod &lt;- lm(bmi ~ age, data = bmi.data)\nsummary(age.mod)\n\n\nCall:\nlm(formula = bmi ~ age, data = bmi.data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.71849 -1.19268  0.01787  1.22263  3.14220 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 18.559837   0.137912  134.58   &lt;2e-16 ***\nage          0.167221   0.002777   60.22   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.408 on 498 degrees of freedom\nMultiple R-squared:  0.8793,    Adjusted R-squared:  0.879 \nF-statistic:  3627 on 1 and 498 DF,  p-value: &lt; 2.2e-16\n\n\n\nsex.mod &lt;- lm(bmi ~ sex, data = bmi.data)\nsummary(sex.mod)\n\n\nCall:\nlm(formula = bmi ~ sex, data = bmi.data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.7079 -3.3001 -0.1313  3.3804  8.6094 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  26.4397     0.2654  99.605   &lt;2e-16 ***\nsexMale      -0.9078     0.3612  -2.513   0.0123 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.026 on 498 degrees of freedom\nMultiple R-squared:  0.01252,   Adjusted R-squared:  0.01054 \nF-statistic: 6.316 on 1 and 498 DF,  p-value: 0.01228\n\n\n\nconsumption.mod &lt;- lm(bmi ~ consumption, data = bmi.data)\nsummary(consumption.mod)\n\n\nCall:\nlm(formula = bmi ~ consumption, data = bmi.data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-8.5273 -3.3595 -0.0708  3.2778  8.1281 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  25.2960     0.6443  39.261   &lt;2e-16 ***\nconsumption   0.9416     0.8909   1.057    0.291    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.047 on 498 degrees of freedom\nMultiple R-squared:  0.002238,  Adjusted R-squared:  0.0002343 \nF-statistic: 1.117 on 1 and 498 DF,  p-value: 0.2911\n\n\nNext, we want to know if the combination of age and sex are better at describing variation in BMI on their own, without including beverage consumption.\n\nage.sex.mod &lt;- lm(bmi ~ age + sex, data = bmi.data)\nsummary(age.sex.mod)\n\n\nCall:\nlm(formula = bmi ~ age + sex, data = bmi.data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.58304 -1.20104 -0.01705  1.23201  2.97899 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 18.75529    0.15760 119.008   &lt;2e-16 ***\nage          0.16668    0.00277  60.165   &lt;2e-16 ***\nsexMale     -0.31748    0.12602  -2.519   0.0121 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.4 on 497 degrees of freedom\nMultiple R-squared:  0.8808,    Adjusted R-squared:  0.8803 \nF-statistic:  1836 on 2 and 497 DF,  p-value: &lt; 2.2e-16\n\n\nWe also want to know whether the combination of age, sex, and beverage consumption is better at describing the variation in BMI than any of the previous models.\n\ncombination.mod &lt;- lm(bmi ~ age + sex + consumption, data = bmi.data)\nsummary(combination.mod)\n\n\nCall:\nlm(formula = bmi ~ age + sex + consumption, data = bmi.data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.67918 -1.18845  0.00031  1.22444  2.48676 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 17.78422    0.26730  66.534  &lt; 2e-16 ***\nage          0.16703    0.00272  61.398  &lt; 2e-16 ***\nsexMale     -0.28402    0.12392  -2.292   0.0223 *  \nconsumption  1.35082    0.30323   4.455 1.04e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.374 on 496 degrees of freedom\nMultiple R-squared:  0.8854,    Adjusted R-squared:  0.8847 \nF-statistic:  1277 on 3 and 496 DF,  p-value: &lt; 2.2e-16\n\n\nFinally, we can check whether the interaction of age, sex, and beverage consumption can explain BMI better than any of the previous models.\n\ninteraction.mod &lt;- lm(bmi ~ age*sex*consumption, data = bmi.data)\nsummary(interaction.mod)\n\n\nCall:\nlm(formula = bmi ~ age * sex * consumption, data = bmi.data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.60668 -1.15255  0.00039  1.24355  2.69427 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)             17.97608    0.80180  22.420   &lt;2e-16 ***\nage                      0.15671    0.01592   9.845   &lt;2e-16 ***\nsexMale                 -0.42385    0.99792  -0.425    0.671    \nconsumption              1.16172    1.07167   1.084    0.279    \nage:sexMale              0.01417    0.02037   0.695    0.487    \nage:consumption          0.01289    0.02149   0.600    0.549    \nsexMale:consumption      0.05629    1.36076   0.041    0.967    \nage:sexMale:consumption -0.01721    0.02811  -0.612    0.541    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.377 on 492 degrees of freedom\nMultiple R-squared:  0.8858,    Adjusted R-squared:  0.8842 \nF-statistic: 545.2 on 7 and 492 DF,  p-value: &lt; 2.2e-16",
    "crumbs": [
      "Cribsheet [Other people's work]",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Akaike information criterion</span>"
    ]
  },
  {
    "objectID": "Akaike_Information_Criterion.html#compare-the-models",
    "href": "Akaike_Information_Criterion.html#compare-the-models",
    "title": "29  Akaike information criterion",
    "section": "29.6 Compare the models",
    "text": "29.6 Compare the models\nTo compare these models and find which one is the best fit for the data, you can put them together into a list and use the aictab() command to compare all of them at once. To use aictab(), first load the library AICcmodavg.\n\nlibrary(AICcmodavg)\n\nThen put the models into a list (‘models’) and name each of them so the AIC table is easier to read (‘model.names’).\n\nmodels &lt;- list(age.mod, sex.mod, consumption.mod, age.sex.mod, combination.mod, interaction.mod)\n\nmodel.names &lt;- c('age.mod', 'sex.mod', 'consumption.mod', 'age.sex.mod', 'combination.mod', 'interaction.mod')\n\nFinally, run aictab() to do the comparison.\n\naictab(cand.set = models, modnames = model.names)\n\n\nModel selection based on AICc:\n\n                K    AICc Delta_AICc AICcWt Cum.Wt       LL\ncombination.mod 5 1743.02       0.00   0.96   0.96  -866.45\ninteraction.mod 9 1749.35       6.33   0.04   1.00  -865.49\nage.sex.mod     4 1760.59      17.57   0.00   1.00  -876.26\nage.mod         3 1764.91      21.89   0.00   1.00  -879.43\nsex.mod         3 2815.68    1072.66   0.00   1.00 -1404.82\nconsumption.mod 3 2820.86    1077.84   0.00   1.00 -1407.41",
    "crumbs": [
      "Cribsheet [Other people's work]",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Akaike information criterion</span>"
    ]
  },
  {
    "objectID": "Akaike_Information_Criterion.html#interpreting-the-results",
    "href": "Akaike_Information_Criterion.html#interpreting-the-results",
    "title": "29  Akaike information criterion",
    "section": "29.7 Interpreting the results",
    "text": "29.7 Interpreting the results\nThe best-fit model is always listed first. The model selection table includes information on:\nK\nThe number of parameters in the model.\nThe default K is 2, so a model with one parameter will have a K of 2 + 1 = 3.\nAICc\nThe information score of the model (the lower-case ‘c’ indicates that the value has been calculated from the AIC test corrected for small sample sizes). The smaller the AIC value, the better the model fit.\nDelta_AICc\nThe difference in AIC score between the best model and the model being compared. In this table, the next-best model has a delta-AIC of 6.69 compared with the top model, and the third-best model has a delta-AIC of 15.96 compared with the top model.\nAICcWt\nAICc weight, which is the proportion of the total amount of predictive power provided by the full set of models contained in the model being assessed. In this case, the top model contains 97% of the total explanation that can be found in the full set of models.\nCum.Wt\nThe sum of the AICc weights. Here the top two models contain 100% of the cumulative AICc weight.\nLL\nLog-likelihood. This is the value describing how likely the model is, given the data. The AIC score is calculated from the LL and K.\nFrom this table we can see that the best model is the combination model – the model that includes every parameter but no interactions (bmi ~ age + sex + consumption).\nThe model is much better than all the others, as it carries 96% of the cumulative model weight and has the lowest AIC score. The next-best model is more than 2 AIC units higher than the best model (6.33 units) and carries only 4% of the cumulative model weight.\nBased on this comparison, we would choose the combination model to use in our data analysis.",
    "crumbs": [
      "Cribsheet [Other people's work]",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Akaike information criterion</span>"
    ]
  },
  {
    "objectID": "Akaike_Information_Criterion.html#reporting-the-results",
    "href": "Akaike_Information_Criterion.html#reporting-the-results",
    "title": "29  Akaike information criterion",
    "section": "29.8 Reporting the results",
    "text": "29.8 Reporting the results\nIf you are using AIC model selection in your research, you can state this in your methods section. Report that you used AIC model selection, briefly explain the best-fit model you found, and state the AIC weight of the model.",
    "crumbs": [
      "Cribsheet [Other people's work]",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Akaike information criterion</span>"
    ]
  },
  {
    "objectID": "Akaike_Information_Criterion.html#example-methods",
    "href": "Akaike_Information_Criterion.html#example-methods",
    "title": "29  Akaike information criterion",
    "section": "29.9 Example methods",
    "text": "29.9 Example methods\nWe used AIC model selection to distinguish among a set of possible models describing the relationship between age, sex, sweetened beverage consumption, and body mass index. The best-fit model, carrying 97% of the cumulative model weight, included every parameter with no interaction effects.\nAfter finding the best-fit model you can go ahead and run the model and evaluate the results. The output of your model evaluation can be reported in the results section of your paper.",
    "crumbs": [
      "Cribsheet [Other people's work]",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Akaike information criterion</span>"
    ]
  },
  {
    "objectID": "R_basics.html",
    "href": "R_basics.html",
    "title": "1  Basics of R",
    "section": "",
    "text": "1.1 Load Libraries\nLibraries (also known as packages) allow R to do things it can’t do out of the box.\nYou can install packages using the install.packages(\"packagename\") syntax. If you haven’t used R before then you should first install the tidyverse packages by typing install.packages(\"tidyverse\")\nYou should always load the libraries you’ll be using at the top of your script.\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors",
    "crumbs": [
      "R | RStudio",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of R</span>"
    ]
  },
  {
    "objectID": "R_basics.html#write-csv-files",
    "href": "R_basics.html#write-csv-files",
    "title": "1  Basics of R",
    "section": "1.2 Write CSV files",
    "text": "1.2 Write CSV files\nWe’ll be using the iris dataset, which is built in and which can be accessed by typing iris.\nWe need a toy dataset to work with, so let’s start by saving a copy of iris as a csv file. This is backwards from what we normally do, which is to save a data set at the end, but will serve our purpose here.\n\nwrite_csv(iris, \"iris.csv\")  # Saving to CSV\n\nCheck that it appears in the files list on the right",
    "crumbs": [
      "R | RStudio",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of R</span>"
    ]
  },
  {
    "objectID": "R_basics.html#read-csv-files",
    "href": "R_basics.html#read-csv-files",
    "title": "1  Basics of R",
    "section": "1.3 Read CSV files",
    "text": "1.3 Read CSV files\nNext let’s read the file back in and assign it to a data frame\nThe &lt;- symbol assigns the data contained in the file to an object in the R environment.\nYou can have as many or as few objects as you need.\n\niris_data &lt;- read_csv(\"iris.csv\")\n\nRows: 150 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Species\ndbl (4): Sepal.Length, Sepal.Width, Petal.Length, Petal.Width\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe messages are important. Check which variables have been assigned to which class\n\nchr:\n\nFull Form: character\nUsed for columns containing text data (strings).\n\ndbl or num:\n\nFull Form: double/number\nRepresents floating-point numbers (numeric values with decimal places).\nThis is the most common numeric data type used in R for real numbers.\n\nint:\n\nFull Form: integer\nUsed for whole numbers.\n\nlgl:\n\nFull Form: logical\nUsed for boolean (TRUE/FALSE) values.\n\nfct:\n\nFull Form: factor\nUsed for categorical data (discrete values like categories, levels, or groups).\n\ndttm:\n\nFull Form: date-time\nRepresents date and time objects (POSIXct class) which include both date and time information.\n\ndate:\n\nFull Form: Date\nUsed for date objects, containing only date information (year, month, day).\n\ntime:\n\nFull Form: time\nUsed for time objects (sometimes seen when working with time series data, though less common than date or POSIXct).\n\nlst:\n\nFull Form: list\nRepresents a list column, which can hold any type of R object, including vectors, data frames, or even other lists.",
    "crumbs": [
      "R | RStudio",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of R</span>"
    ]
  },
  {
    "objectID": "R_basics.html#look-at-the-structure-of-an-object",
    "href": "R_basics.html#look-at-the-structure-of-an-object",
    "title": "1  Basics of R",
    "section": "1.4 Look at the structure of an object",
    "text": "1.4 Look at the structure of an object\n\nstr(iris_data)\n\nspc_tbl_ [150 × 5] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Sepal.Length: num [1:150] 5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num [1:150] 3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num [1:150] 1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num [1:150] 0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : chr [1:150] \"setosa\" \"setosa\" \"setosa\" \"setosa\" ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Sepal.Length = col_double(),\n  ..   Sepal.Width = col_double(),\n  ..   Petal.Length = col_double(),\n  ..   Petal.Width = col_double(),\n  ..   Species = col_character()\n  .. )\n - attr(*, \"problems\")=&lt;externalptr&gt;",
    "crumbs": [
      "R | RStudio",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of R</span>"
    ]
  },
  {
    "objectID": "R_basics.html#look-at-the-contents-of-an-object",
    "href": "R_basics.html#look-at-the-contents-of-an-object",
    "title": "1  Basics of R",
    "section": "1.5 Look at the contents of an object",
    "text": "1.5 Look at the contents of an object\n\niris_data\n\n# A tibble: 150 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# ℹ 140 more rows\n\n\n\n1.5.1 Summary of the data set\n\nsummary(iris_data)\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n   Species         \n Length:150        \n Class :character  \n Mode  :character",
    "crumbs": [
      "R | RStudio",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of R</span>"
    ]
  },
  {
    "objectID": "R_basics.html#pipes",
    "href": "R_basics.html#pipes",
    "title": "1  Basics of R",
    "section": "1.6 Pipes",
    "text": "1.6 Pipes\nThe %&gt;% pipe operator, commonly called the “pipe,” is one of the most important tools in the tidyverse. It is used to pass the result of one function into the next function, making your code cleaner and easier to read by chaining operations together.\n\n1.6.1 How the Pipe Works:\nThe pipe takes the output of the expression on its left and passes it as the first argument to the function on its right.\n\\[ \\texttt{result} \\leftarrow \\texttt{data} \\\\ \\hspace{2cm} \\% \\! &gt; \\! \\% \\, \\texttt{operation}_1 \\\\ \\hspace{2cm} \\% \\! &gt; \\! \\% \\, \\texttt{operation}_2 \\\\ \\hspace{2cm} \\vdots \\\\ \\hspace{2cm} \\% \\! &gt; \\! \\% \\, \\texttt{operation}_n\\]\n\n\n1.6.2 Simple Explanation:\n\nWithout the pipe, you would need to nest functions, which can make the code harder to read:\n\nsummarise(group_by(filter(df, Species == \"setosa\"), Species), mean_length = mean(Sepal.Length))\n\nWith the %&gt;% pipe, you can write it more readable by breaking each step down:\n\niris_data %&gt;%\n  filter(Sepal.Length &gt;5.8) %&gt;%\n  group_by(Species) %&gt;%\n  summarise(mean_length = mean(Sepal.Length))\n\n# A tibble: 2 × 2\n  Species    mean_length\n  &lt;chr&gt;            &lt;dbl&gt;\n1 versicolor        6.34\n2 virginica         6.72\n\n\n\n\n\n1.6.3 Benefits of Using the Pipe:\n\nImproves readability: It reads like a logical sequence of steps.\nReduces the need for intermediate variables: You don’t need to create multiple intermediate objects.\nSimplifies function chaining: Functions are applied one after the other, making it clear what happens at each step.",
    "crumbs": [
      "R | RStudio",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of R</span>"
    ]
  },
  {
    "objectID": "R_basics.html#single-table-verbs-basic",
    "href": "R_basics.html#single-table-verbs-basic",
    "title": "1  Basics of R",
    "section": "1.7 Single Table Verbs (basic)",
    "text": "1.7 Single Table Verbs (basic)\nAll the main actions in tidyverse take a tibble (the new name for a dataframe), do something with it and then return another tibble. These are the ‘single table verbs’.\n\nThese are the main functions you’ll need to learn.\nAll of them accept lists, where you separate items with a comma.\n\n\n1.7.1 Filter\n\nfilter():\n\nFilters rows based on specified conditions.\nReturns only the rows that meet the condition(s).\n\n\n\niris_data %&gt;% \n  filter(\n    Species == \"setosa\",\n    Sepal.Length &gt; 4.3)\n\n# A tibble: 49 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# ℹ 39 more rows\n\n\n\n\n1.7.2 Logic\n\nYou can provide logical operators` to any verb to make complex queries\n\n== Equals\n!= Not Equals\n&gt; more than\n&lt; less than\n&gt;= more than or equal to\n&lt;= less than or equal to\n| or\n& and\n! not\n+ add\n- subtract\n%% modulo\n\n\n\n\n1.7.3 AND (&)\nFiltering rows where Sepal.Length is greater than 5 AND Species is not setosa\n\niris_data %&gt;% \n  filter(\n    Sepal.Length &gt; 5 & Species != \"setosa\"\n    )\n\n# A tibble: 96 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species   \n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;     \n 1          7           3.2          4.7         1.4 versicolor\n 2          6.4         3.2          4.5         1.5 versicolor\n 3          6.9         3.1          4.9         1.5 versicolor\n 4          5.5         2.3          4           1.3 versicolor\n 5          6.5         2.8          4.6         1.5 versicolor\n 6          5.7         2.8          4.5         1.3 versicolor\n 7          6.3         3.3          4.7         1.6 versicolor\n 8          6.6         2.9          4.6         1.3 versicolor\n 9          5.2         2.7          3.9         1.4 versicolor\n10          5.9         3            4.2         1.5 versicolor\n# ℹ 86 more rows\n\n\n\n\n1.7.4 OR (|)\nFiltering rows where Sepal.Length is less than 5 OR Species is setosa\n\niris_data %&gt;% \n  filter(\n    Sepal.Length &lt; 5 | Species == \"setosa\"\n    )\n\n# A tibble: 52 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  \n 1          5.1         3.5          1.4         0.2 setosa \n 2          4.9         3            1.4         0.2 setosa \n 3          4.7         3.2          1.3         0.2 setosa \n 4          4.6         3.1          1.5         0.2 setosa \n 5          5           3.6          1.4         0.2 setosa \n 6          5.4         3.9          1.7         0.4 setosa \n 7          4.6         3.4          1.4         0.3 setosa \n 8          5           3.4          1.5         0.2 setosa \n 9          4.4         2.9          1.4         0.2 setosa \n10          4.9         3.1          1.5         0.1 setosa \n# ℹ 42 more rows\n\n\n\n\n1.7.5 NOT (!)\nFiltering rows where Species is NOT “setosa” by negating the test with ! placed at the start. Compare to above where != was used for not-equal. Here it tests if the species equals setosa, then returns all rows where that is NOT true.\n\niris_data %&gt;% \n  filter(\n    !(Species == \"setosa\")\n    )\n\n# A tibble: 100 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species   \n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;     \n 1          7           3.2          4.7         1.4 versicolor\n 2          6.4         3.2          4.5         1.5 versicolor\n 3          6.9         3.1          4.9         1.5 versicolor\n 4          5.5         2.3          4           1.3 versicolor\n 5          6.5         2.8          4.6         1.5 versicolor\n 6          5.7         2.8          4.5         1.3 versicolor\n 7          6.3         3.3          4.7         1.6 versicolor\n 8          4.9         2.4          3.3         1   versicolor\n 9          6.6         2.9          4.6         1.3 versicolor\n10          5.2         2.7          3.9         1.4 versicolor\n# ℹ 90 more rows\n\n\n\n\n1.7.6 \n\n\n1.7.7 Arrange\n\narrange():\n\nOrders rows of a tibble by one or more columns.\nCan sort in ascending or descending order.\nUsing a list will sort by item 1, then item 2, then item 3.\nAs with filter, this function can accept a list of actions that are carried out sequentially\n\n\n\niris_data %&gt;% \n  arrange(\n    Sepal.Length,\n    Sepal.Width,\n    Species\n    )\n\n# A tibble: 150 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;  \n 1          4.3         3            1.1         0.1 setosa \n 2          4.4         2.9          1.4         0.2 setosa \n 3          4.4         3            1.3         0.2 setosa \n 4          4.4         3.2          1.3         0.2 setosa \n 5          4.5         2.3          1.3         0.3 setosa \n 6          4.6         3.1          1.5         0.2 setosa \n 7          4.6         3.2          1.4         0.2 setosa \n 8          4.6         3.4          1.4         0.3 setosa \n 9          4.6         3.6          1           0.2 setosa \n10          4.7         3.2          1.3         0.2 setosa \n# ℹ 140 more rows\n\n\n\niris_data %&gt;% \n  arrange(\n    !Sepal.Length,\n    Sepal.Width,\n    Species\n    )\n\n# A tibble: 150 × 5\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species   \n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;     \n 1          5           2            3.5         1   versicolor\n 2          6           2.2          4           1   versicolor\n 3          6.2         2.2          4.5         1.5 versicolor\n 4          6           2.2          5           1.5 virginica \n 5          4.5         2.3          1.3         0.3 setosa    \n 6          5.5         2.3          4           1.3 versicolor\n 7          6.3         2.3          4.4         1.3 versicolor\n 8          5           2.3          3.3         1   versicolor\n 9          4.9         2.4          3.3         1   versicolor\n10          5.5         2.4          3.8         1.1 versicolor\n# ℹ 140 more rows\n\n\n\n\n1.7.8 Select\n\nselect():\n\nSelects specific columns from a data frame or tibble.\nUseful for reducing data to only the columns of interest.\nAs with other verbs, a sequential set of actions is possible\n\n\n\niris_data %&gt;% \n  select(\n    Sepal.Length, \n    Species\n    )\n\n# A tibble: 150 × 2\n   Sepal.Length Species\n          &lt;dbl&gt; &lt;chr&gt;  \n 1          5.1 setosa \n 2          4.9 setosa \n 3          4.7 setosa \n 4          4.6 setosa \n 5          5   setosa \n 6          5.4 setosa \n 7          4.6 setosa \n 8          5   setosa \n 9          4.4 setosa \n10          4.9 setosa \n# ℹ 140 more rows\n\n\n\nIt’s also possible to negate an action,\n\n\niris_data %&gt;% \n  select(\n    !Species\n    )\n\n# A tibble: 150 × 4\n   Sepal.Length Sepal.Width Petal.Length Petal.Width\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt;\n 1          5.1         3.5          1.4         0.2\n 2          4.9         3            1.4         0.2\n 3          4.7         3.2          1.3         0.2\n 4          4.6         3.1          1.5         0.2\n 5          5           3.6          1.4         0.2\n 6          5.4         3.9          1.7         0.4\n 7          4.6         3.4          1.4         0.3\n 8          5           3.4          1.5         0.2\n 9          4.4         2.9          1.4         0.2\n10          4.9         3.1          1.5         0.1\n# ℹ 140 more rows\n\n\n\n\n1.7.9 Mutate\n\nmutate():\n\nAdds new columns or modifies existing columns in a tibble.\nCommonly used for creating calculated columns.\n\n\n\niris_data %&gt;%\n  mutate(\n    Petal.Ratio = Petal.Length / Petal.Width,\n    Petal.Area = Petal.Length * Petal.Width\n         )\n\n# A tibble: 150 × 7\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species Petal.Ratio\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;\n 1          5.1         3.5          1.4         0.2 setosa         7   \n 2          4.9         3            1.4         0.2 setosa         7   \n 3          4.7         3.2          1.3         0.2 setosa         6.5 \n 4          4.6         3.1          1.5         0.2 setosa         7.5 \n 5          5           3.6          1.4         0.2 setosa         7   \n 6          5.4         3.9          1.7         0.4 setosa         4.25\n 7          4.6         3.4          1.4         0.3 setosa         4.67\n 8          5           3.4          1.5         0.2 setosa         7.5 \n 9          4.4         2.9          1.4         0.2 setosa         7   \n10          4.9         3.1          1.5         0.1 setosa        15   \n# ℹ 140 more rows\n# ℹ 1 more variable: Petal.Area &lt;dbl&gt;\n\n\n\n\n1.7.10 Pivot_longer\n\npivot_longer():\n\nConverts wide data to long format (stacking columns into rows).\nUseful for transforming data when working with multiple measurement columns.\nWe’ll use relig_income as an example data set. This is in WIDE format.\n\n\n\nrelig_income\n\n# A tibble: 18 × 11\n   religion `&lt;$10k` `$10-20k` `$20-30k` `$30-40k` `$40-50k` `$50-75k` `$75-100k`\n   &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 Agnostic      27        34        60        81        76       137        122\n 2 Atheist       12        27        37        52        35        70         73\n 3 Buddhist      27        21        30        34        33        58         62\n 4 Catholic     418       617       732       670       638      1116        949\n 5 Don’t k…      15        14        15        11        10        35         21\n 6 Evangel…     575       869      1064       982       881      1486        949\n 7 Hindu          1         9         7         9        11        34         47\n 8 Histori…     228       244       236       238       197       223        131\n 9 Jehovah…      20        27        24        24        21        30         15\n10 Jewish        19        19        25        25        30        95         69\n11 Mainlin…     289       495       619       655       651      1107        939\n12 Mormon        29        40        48        51        56       112         85\n13 Muslim         6         7         9        10         9        23         16\n14 Orthodox      13        17        23        32        32        47         38\n15 Other C…       9         7        11        13        13        14         18\n16 Other F…      20        33        40        46        49        63         46\n17 Other W…       5         2         3         4         2         7          3\n18 Unaffil…     217       299       374       365       341       528        407\n# ℹ 3 more variables: `$100-150k` &lt;dbl&gt;, `&gt;150k` &lt;dbl&gt;,\n#   `Don't know/refused` &lt;dbl&gt;\n\n\n\nTo pivot this data set, we provide\n\ncols = : The columns that will be used to pivot in to the new ‘values’ column. Here we want all columns from the dataset except the religion column which provides the labels, so simply exclude that one with !religion. You could also specify specific columns with a list cols = c(\"&lt;$10k\",\"$10-20k\",\"$20-30k\")\n\n\n\nrelig_income_long &lt;- relig_income %&gt;%\n    pivot_longer(\n      cols = !religion, \n      names_to = \"income\", \n      values_to = \"n\")\n\nrelig_income_long\n\n# A tibble: 180 × 3\n   religion income                 n\n   &lt;chr&gt;    &lt;chr&gt;              &lt;dbl&gt;\n 1 Agnostic &lt;$10k                 27\n 2 Agnostic $10-20k               34\n 3 Agnostic $20-30k               60\n 4 Agnostic $30-40k               81\n 5 Agnostic $40-50k               76\n 6 Agnostic $50-75k              137\n 7 Agnostic $75-100k             122\n 8 Agnostic $100-150k            109\n 9 Agnostic &gt;150k                 84\n10 Agnostic Don't know/refused    96\n# ℹ 170 more rows\n\n\n\n\n1.7.11 Pivot_wider\nThis is the exact opposite of pivot_longer. You’ll be taking the values of a column (here income) that you want to pivot to be the new column names in the wide format tibble, then distributing the values of another column (here count) to the appropriate columns and rows (here religion).\n\nrelig_income_long %&gt;%\n  pivot_wider(\n    id_cols = religion,\n    names_from = income, \n    values_from = n\n    )\n\n# A tibble: 18 × 11\n   religion `&lt;$10k` `$10-20k` `$20-30k` `$30-40k` `$40-50k` `$50-75k` `$75-100k`\n   &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 Agnostic      27        34        60        81        76       137        122\n 2 Atheist       12        27        37        52        35        70         73\n 3 Buddhist      27        21        30        34        33        58         62\n 4 Catholic     418       617       732       670       638      1116        949\n 5 Don’t k…      15        14        15        11        10        35         21\n 6 Evangel…     575       869      1064       982       881      1486        949\n 7 Hindu          1         9         7         9        11        34         47\n 8 Histori…     228       244       236       238       197       223        131\n 9 Jehovah…      20        27        24        24        21        30         15\n10 Jewish        19        19        25        25        30        95         69\n11 Mainlin…     289       495       619       655       651      1107        939\n12 Mormon        29        40        48        51        56       112         85\n13 Muslim         6         7         9        10         9        23         16\n14 Orthodox      13        17        23        32        32        47         38\n15 Other C…       9         7        11        13        13        14         18\n16 Other F…      20        33        40        46        49        63         46\n17 Other W…       5         2         3         4         2         7          3\n18 Unaffil…     217       299       374       365       341       528        407\n# ℹ 3 more variables: `$100-150k` &lt;dbl&gt;, `&gt;150k` &lt;dbl&gt;,\n#   `Don't know/refused` &lt;dbl&gt;\n\n\n\n\n1.7.12 Using pipes and verbs together\nTo do a series of things to a tibble, you simply pipe the verbs\n\nrelig_income %&gt;%\n    pivot_longer(  \n      cols = !religion, \n      names_to = \"income\", \n      values_to = \"count\") %&gt;% \n\n    filter(\n      income != \"Don't know/refused\"\n          ) %&gt;% \n\n    arrange(\n      income,\n      religion\n          )\n\n# A tibble: 162 × 3\n   religion                income  count\n   &lt;chr&gt;                   &lt;chr&gt;   &lt;dbl&gt;\n 1 Agnostic                $10-20k    34\n 2 Atheist                 $10-20k    27\n 3 Buddhist                $10-20k    21\n 4 Catholic                $10-20k   617\n 5 Don’t know/refused      $10-20k    14\n 6 Evangelical Prot        $10-20k   869\n 7 Hindu                   $10-20k     9\n 8 Historically Black Prot $10-20k   244\n 9 Jehovah's Witness       $10-20k    27\n10 Jewish                  $10-20k    19\n# ℹ 152 more rows\n\n\n\nYou can include notes if it helps you.\nUsing indentation also really helps\n\n\nrelig_income %&gt;%\n  \n    # Pivot the table to be long format\n    pivot_longer(  \n      cols = !religion, \n      names_to = \"income\", \n      values_to = \"count\") %&gt;% \n  \n    # Remove lines where no income data was provided\n    filter(\n      income != \"Don't know/refused\"\n          ) %&gt;% \n  \n    # Sort the data to sho \n    arrange(\n      income,\n      religion\n          )\n\n# A tibble: 162 × 3\n   religion                income  count\n   &lt;chr&gt;                   &lt;chr&gt;   &lt;dbl&gt;\n 1 Agnostic                $10-20k    34\n 2 Atheist                 $10-20k    27\n 3 Buddhist                $10-20k    21\n 4 Catholic                $10-20k   617\n 5 Don’t know/refused      $10-20k    14\n 6 Evangelical Prot        $10-20k   869\n 7 Hindu                   $10-20k     9\n 8 Historically Black Prot $10-20k   244\n 9 Jehovah's Witness       $10-20k    27\n10 Jewish                  $10-20k    19\n# ℹ 152 more rows\n\n\n\n\n1.7.13 Group_by\n\nThese verbs create a data frame with one row per group, where the variables are a summary of values. group_by groups data by one or more columns,\n\ngroup_by allows you to create groupwise calculations like group means\nThis approach does not collapse the data, so if you wanted three rows, with a single mean value for each one, you need to do something else (see below).\nAlways ungroup() if you plan to do further calculations on individual rows.\n\niris %&gt;% \n  group_by(Species) %&gt;% \n  mutate(\n    Sepal.length.mean = mean(Sepal.Length),\n    weight = Sepal.Length - Sepal.length.mean\n  )%&gt;% \n  ungroup()\n\n# A tibble: 150 × 7\n   Sepal.Length Sepal.Width Petal.Length Petal.Width Species Sepal.length.mean\n          &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;fct&gt;               &lt;dbl&gt;\n 1          5.1         3.5          1.4         0.2 setosa               5.01\n 2          4.9         3            1.4         0.2 setosa               5.01\n 3          4.7         3.2          1.3         0.2 setosa               5.01\n 4          4.6         3.1          1.5         0.2 setosa               5.01\n 5          5           3.6          1.4         0.2 setosa               5.01\n 6          5.4         3.9          1.7         0.4 setosa               5.01\n 7          4.6         3.4          1.4         0.3 setosa               5.01\n 8          5           3.4          1.5         0.2 setosa               5.01\n 9          4.4         2.9          1.4         0.2 setosa               5.01\n10          4.9         3.1          1.5         0.1 setosa               5.01\n# ℹ 140 more rows\n# ℹ 1 more variable: weight &lt;dbl&gt;\n\n\n\nSummarise() and reframe() are almost always used in combination with group_by().\nAs with all verbs, you can provide lists to group_by(), reframe() and summarise().\n1.7.14 Reframe\n\nPurpose: A more flexible way to return multiple results for each group without reducing it to one row per group.\nTypical Use: Used when you want to keep multiple rows per group but still perform summary operations. i.e. when creating denominators etc.\nBehavior: Allows for returning multiple rows or multiple values for each group, so it doesn’t necessarily collapse the data.\nIf you choose to include any of the original variables in your reframed tibble, the resulting tibble will have the same dimensions as your original. Here the groupwise counts are added to count and the groupwise mean sepal lengths are added to mean.sepal.length.\n\n\niris_data %&gt;%\n  group_by(Species) %&gt;%\n  reframe(\n    Sepal.Length,\n    Sepal.Width,\n    count = n(),\n    sepal.length.mean = mean(Sepal.Length),\n    weight = Sepal.Length-sepal.length.mean\n  ) \n\n# A tibble: 150 × 6\n   Species Sepal.Length Sepal.Width count sepal.length.mean   weight\n   &lt;chr&gt;          &lt;dbl&gt;       &lt;dbl&gt; &lt;int&gt;             &lt;dbl&gt;    &lt;dbl&gt;\n 1 setosa           5.1         3.5    50              5.01  0.0940 \n 2 setosa           4.9         3      50              5.01 -0.106  \n 3 setosa           4.7         3.2    50              5.01 -0.306  \n 4 setosa           4.6         3.1    50              5.01 -0.406  \n 5 setosa           5           3.6    50              5.01 -0.00600\n 6 setosa           5.4         3.9    50              5.01  0.394  \n 7 setosa           4.6         3.4    50              5.01 -0.406  \n 8 setosa           5           3.4    50              5.01 -0.00600\n 9 setosa           4.4         2.9    50              5.01 -0.606  \n10 setosa           4.9         3.1    50              5.01 -0.106  \n# ℹ 140 more rows\n\n\n\nIf you choose not to include your original variables, reframe() will present only the new variables.\n\niris %&gt;%\n  group_by(Species) %&gt;%\n  reframe(\n    count = n(),\n    mean.sepal.length = mean(Sepal.Length),\n    median.petal.length = median(Petal.Length),\n    sd.petal.length = sd(Petal.Length)\n  )\n\n# A tibble: 3 × 5\n  Species    count mean.sepal.length median.petal.length sd.petal.length\n  &lt;fct&gt;      &lt;int&gt;             &lt;dbl&gt;               &lt;dbl&gt;           &lt;dbl&gt;\n1 setosa        50              5.01                1.5            0.174\n2 versicolor    50              5.94                4.35           0.470\n3 virginica     50              6.59                5.55           0.552\n\n\n\nsummarise():\n\nCreates summary statistics for each group, such as mean, median, or sum.\nIn this case summarise() creates the same table as the previous example of reframe\nThis shows how you can always use reframe so generally forget about using summarise()\n\n\n\niris_data %&gt;%\n  group_by(Species) %&gt;%\n  summarise(\n    count = n(),\n    mean.sepal.length = mean(Sepal.Length),\n    median.petal.length = median(Petal.Length)\n            )\n\n# A tibble: 3 × 4\n  Species    count mean.sepal.length median.petal.length\n  &lt;chr&gt;      &lt;int&gt;             &lt;dbl&gt;               &lt;dbl&gt;\n1 setosa        50              5.01                1.5 \n2 versicolor    50              5.94                4.35\n3 virginica     50              6.59                5.55\n\n\n\n\n1.7.15 Rename\n\nrename():\n\nRenames columns in a tibble.\nHelpful for cleaning up column names for clarity.\n\n\n\niris_data %&gt;% \n  rename(\n    var_a = Petal.Length,\n    var_b = Petal.Width\n    )\n\n# A tibble: 150 × 5\n   Sepal.Length Sepal.Width var_a var_b Species\n          &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;  \n 1          5.1         3.5   1.4   0.2 setosa \n 2          4.9         3     1.4   0.2 setosa \n 3          4.7         3.2   1.3   0.2 setosa \n 4          4.6         3.1   1.5   0.2 setosa \n 5          5           3.6   1.4   0.2 setosa \n 6          5.4         3.9   1.7   0.4 setosa \n 7          4.6         3.4   1.4   0.3 setosa \n 8          5           3.4   1.5   0.2 setosa \n 9          4.4         2.9   1.4   0.2 setosa \n10          4.9         3.1   1.5   0.1 setosa \n# ℹ 140 more rows",
    "crumbs": [
      "R | RStudio",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of R</span>"
    ]
  },
  {
    "objectID": "R_basics.html#ggplot",
    "href": "R_basics.html#ggplot",
    "title": "1  Basics of R",
    "section": "1.9 ggplot",
    "text": "1.9 ggplot\nNow we’ve covered the basics of managing and manipulating tibbles, let’s look at the basics of drawing charts in ggplot.\nTo understand the syntax of ggplot, you have to understand how charts created with this system are built in layers. Just like how we pipe data through %&gt;% when handling tibbles, we add new layers to ggplot charts using +\nggplot accepts piped data as an input. The initial ggplot is a blank chart with no axes. Let’s pipe the iris tibble in to a ggplot.\n\niris %&gt;% \n  ggplot() \n\n\n\n\n\n\n\n\nNext we want to describe the ‘aesthetics’ of the plot. This is how we define the variables that will contribute to the axes, groups, points, shapes, fills, areas and so on.\nLet’s provide ggplot with some aesthetics in the form of an x (Sepal.Length) and y (Sepal.Width)\nThis should add the axes which will be appropriately scaled according to the limits of the two variables.\n\niris %&gt;% \n  ggplot(aes(x = Sepal.Length,y = Sepal.Width)) \n\n\n\n\n\n\n\n\nTo add some of the data points to the chart, we need to add a new layer. The type of chart is defined by which “geom\" layer you choose to add next.\nLet’s start simple and draw some points with geom_point(). Remember to add the new layer by putting a + at the end of the last line\n\niris %&gt;% \n    ggplot(\n      aes(\n        Sepal.Length,\n        Sepal.Width)\n          ) +\n      geom_point()\n\n\n\n\n\n\n\n\nThis is useful, but doesn’t tell us anything about the points. Colours, grouping, fills etc are defined in the aesthethics, so let’s add some colours to the points according to which species they represent.\nYou can encode colours with color= or colour=\n\niris %&gt;% \n    ggplot(\n      aes(\n        Sepal.Length,\n        Sepal.Width,\n        color=Species\n        )\n          ) +\n      geom_point()\n\n\n\n\n\n\n\n\nIf you provide a continuous variable to color you’ll get a nice result too.\n\niris %&gt;% \n    ggplot(\n      aes(\n        Sepal.Length,\n        Sepal.Width,\n        color=Petal.Length\n        )\n          ) +\n      geom_point()\n\n\n\n\n\n\n\n\nYou can also use the shape= aesthetic to add different shapes. Here we can now see information on sepal length (x), sepal width (y), species (shape) and petal length (color).\n\niris %&gt;% \n    ggplot(\n      aes(\n        Sepal.Length,\n        Sepal.Width,\n        color=Petal.Length,\n        shape=Species\n        )\n          ) +\n      geom_point()\n\n\n\n\n\n\n\n\nYou can also use the size= aesthetic to get a very different plot.\n\niris %&gt;% \n    ggplot(\n      aes(\n        Sepal.Length,\n        Sepal.Width,\n        color=Species,\n        size=Petal.Length\n        )\n          ) +\n      geom_point()\n\n\n\n\n\n\n\n\n\n1.9.1 Line charts\ngeom_line() draws lines between points\n\niris %&gt;% \n    ggplot(\n      aes(\n        Sepal.Length,\n        Sepal.Width,\n        )\n          ) +\n      geom_line()\n\n\n\n\n\n\n\n\nIn this case, that makes little sense, because there’s three species. Adding the colour aesthethic groups the data and the lines will be drawn by group\n\niris %&gt;% \n    ggplot(\n      aes(\n        Sepal.Length,\n        Sepal.Width,\n        color=Species,\n        )\n          ) +\n      geom_line()\n\n\n\n\n\n\n\n\nYou can combine more than one geom by adding extra layers\n\niris %&gt;% \n    ggplot(\n      aes(\n        Sepal.Length,\n        Sepal.Width,\n        color=Species,\n        )\n          ) +\n      geom_line()+\n      geom_point()\n\n\n\n\n\n\n\n\nand there’s variations like geom_smooth() which makes a nicer line\n\niris %&gt;% \n    ggplot(\n      aes(\n        Sepal.Length,\n        Sepal.Width,\n        color=Species,\n        )\n          ) +\n      geom_smooth()+\n      geom_point()\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n1.9.2 Facets\nFacets allow you to draw multiple panels. facet_grid is a nice way to do this.\nWe’ll facet the line chart by Species. The facet is an arrangement of panels in columns and rows.\nto arrange your facets in rows you provide facet_grid(.~Species)\n\niris %&gt;% \n    ggplot(\n      aes(\n        Sepal.Length,\n        Sepal.Width,\n        color=Species,\n        )\n          ) +\n      geom_smooth()+\n      geom_point()+\n  facet_grid(.~Species)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nTo arrange your facets in columns you provide `facet_grid(Species~.)\n\niris %&gt;% \n    ggplot(\n      aes(\n        Sepal.Length,\n        Sepal.Width,\n        color=Species,\n        )\n          ) +\n      geom_smooth()+\n      geom_point()+\n  facet_grid(Species~.)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nTo arrange your facets around species in columns and on petal size in rows you could do\n\niris %&gt;% \n  mutate(\n    petal_bigger_than_average = Petal.Length &gt;= mean(Petal.Length) \n  ) %&gt;% \n    ggplot(\n      aes(\n        Sepal.Length,\n        Sepal.Width,\n        color=Species,\n        )\n          ) +\n      geom_smooth()+\n      geom_point()+\n  facet_grid(\n    petal_bigger_than_average ~  Species\n    )\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nA problem with facets can be to do with axes being locked to the minimum and maximum values of the variable. You may wish to ‘free’ the axes using scales=\"free\", scales=\"free_x\" or scales=\"free_y\"\n\niris %&gt;% \n    ggplot(\n      aes(\n        Sepal.Length,\n        Sepal.Width,\n        color=Species,\n        )\n          ) +\n      geom_smooth()+\n      geom_point()+\n  facet_grid(\n            Petal.Length &gt;= mean(Petal.Length) ~ Species, \n            scales = \"free\"\n            )\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\nFinally we can see a linear relationship in some of the data. Setosa for instance has a strong correlation between sepal length and sepal width, which does not appear to be true of the other species, regardless of the petal length division.\n\n\n1.9.3 Bar chart\ngeom_bar() – Creates bar plots, either stacked or grouped.\n-   Example: `geom_bar(stat = \"identity\")` for bar heights based on a variable.\nTo plot a count of occurrances in the data use stat=\"count\"\nThe default is a stacked bar chart. For this you only need to provide x.\n\niris_data %&gt;% \n    ggplot(\n      aes(\n        Petal.Length &gt; 4,\n        fill = Species\n        )\n          )+\n  geom_bar(stat=\"count\")\n\n\n\n\n\n\n\n\nYou can change this to a side-by-side chart using `position=“dodge”\n\niris %&gt;% \n    ggplot(\n      aes(\n        Petal.Length &gt; 4,\n        fill = Species\n        )\n          )+\n  geom_bar(stat=\"count\",\n           position = \"dodge\"\n           )\n\n\n\n\n\n\n\n\n\niris %&gt;% \n    ggplot(\n      aes(\n        Petal.Length &gt; 4,\n        fill = Species\n        )\n          )+\n  geom_bar(stat=\"count\"           )+\n  facet_grid(.~Species)\n\n\n\n\n\n\n\n\nIn lots of cases you’ll have precomputed some summaries and will want to print the exact identity values. Let’s reframe the iris data as a set of averages (see the reframe section) and then pipe the result in to a ggplot using stat=\"identity\" Unlike with the stat=\"count\" default, you need to provide both x (grouping) and x (value) data to stat = \"identity.\n\niris_data %&gt;%\n  group_by(Species) %&gt;%\n  reframe(\n    count = n(),\n    mean.sepal.length = mean(Sepal.Length),\n    median.petal.length = median(Petal.Length)\n  ) %&gt;% \n  \n  ggplot(\n    aes(\n      Species,\n      mean.sepal.length,\n      fill=Species  \n      )\n        )+\n  geom_bar(stat=\"identity\")\n\n\n\n\n\n\n\n\n\n\n1.9.4 Columnar charts\ngeom_col() – Similar to geom_bar(), but used when heights are defined by variables instead of counts.\n-   Example: `geom_col()`\nThis is essentially identical to using stat=\"identity\" with a geom_bar()\nWe can also use geom_errorbar() to add confidence intervals.\nNote that geom_errorbar has its own set of aesthethics, to cover the upper (ymax) and lower (ymin) limits.\nLet’s start by making some statistics\n\niris %&gt;%\n  group_by(Species) %&gt;%\n  reframe(\n    count = n(),\n    mean.sepal.length = mean(Sepal.Length),\n    sd.sepal.length = sd(Sepal.Length),\n    lower = mean.sepal.length - (1.96*sd.sepal.length),\n    upper = mean.sepal.length + (1.96*sd.sepal.length)\n  ) \n\n# A tibble: 3 × 6\n  Species    count mean.sepal.length sd.sepal.length lower upper\n  &lt;fct&gt;      &lt;int&gt;             &lt;dbl&gt;           &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 setosa        50              5.01           0.352  4.32  5.70\n2 versicolor    50              5.94           0.516  4.92  6.95\n3 virginica     50              6.59           0.636  5.34  7.83\n\n\nThen pipe this in to ggplot\n\niris %&gt;%\n  group_by(Species) %&gt;%\n  reframe(\n    count = n(),\n    mean.sepal.length = mean(Sepal.Length),\n    sd.sepal.length = sd(Sepal.Length),\n    lower = mean.sepal.length - (1.96*sd.sepal.length),\n    upper = mean.sepal.length + (1.96*sd.sepal.length)\n  ) %&gt;% \n  \n  ggplot(\n    aes(\n      Species,\n      mean.sepal.length,\n      fill=Species  \n      )\n        )+\n  geom_col()+\n  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.2)\n\n\n\n\n\n\n\n\n\n\n1.9.5 Histograms\ngeom_histogram() – Plots the frequency distribution of continuous data by creating bins.\n-   Example: `geom_histogram()`\nHistograms require only values of x\n\niris %&gt;%\n  ggplot(\n    aes(\n      Petal.Length\n        )\n        )+\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nYou can control the number of bins\n\niris %&gt;%\n  ggplot(\n    aes(\n      Petal.Length\n        )\n        )+\n  geom_histogram(bins = 50)\n\n\n\n\n\n\n\n\nYou can also add grouping as before\n\niris %&gt;%\n  ggplot(\n    aes(\n      Petal.Length,\n      fill = Species\n        )\n        )+\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n1.9.6 Density plots\ngeom_density() – Shows the distribution of a continuous variable with a smooth density curve.\n-   Example: `geom_density()`\nDensity plots are very useful when you want to look at distributions of data in different classes. They are similar in many respects to histograms.\n\niris %&gt;%\n  ggplot(\n    aes(\n      Petal.Length,\n      fill = Species\n        )\n        )+\n  geom_density()\n\n\n\n\n\n\n\n\nYou’ll want to see what’s going on in the overlapping regions, so you can add transparency with alpha=. Transparency can be used in any ggplot.\n\niris %&gt;%\n  ggplot(\n    aes(\n      Petal.Length,\n      fill = Species\n        )\n        )+\n  geom_density(alpha=0.4)\n\n\n\n\n\n\n\n\n\n\n1.9.7 Boxplots\ngeom_boxplot() – Visualizes the distribution of a variable through quartiles and potential outliers.\n-   Example: `geom_boxplot()`\nThese are a mainstay of epidemiology.\n\niris %&gt;%\n  ggplot(\n    aes(\n      Species,\n      Petal.Length,\n      fill = Species\n        )\n        )+\n  geom_boxplot()\n\n\n\n\n\n\n\n\n\n\n1.9.8 Violin plots\ngeom_violin() – A hybrid of boxplot and density plot, showing distribution shape along with quartiles.\n-   Example: `geom_violin()`\n\niris %&gt;%\n  ggplot(\n    aes(\n      Species,\n      Petal.Length,\n      fill = Species\n        )\n        )+\n  geom_violin()\n\n\n\n\n\n\n\n\n\n1.9.8.1 Violin & Box together\nAdding a geom_box() layer to a violin plot can be useful.\n\niris %&gt;%\n  ggplot(\n    aes(\n      Species,\n      Petal.Length,\n      fill = Species\n        )\n        )+\n  geom_boxplot()+\n  geom_violin()\n\n\n\n\n\n\n\n\nBut this is ugly. and the boxplots are obscured by the violins. The order of the layers in a ggplot matters\n\niris %&gt;%\n  ggplot(\n    aes(\n      Species,\n      Petal.Length,\n      fill = Species\n        )\n        )+\n  geom_violin()+\n  geom_boxplot()\n\n\n\n\n\n\n\n\nChanging the order of the layers improves things, but we can control each layer individually by changing it’s mappings. This is the reason why the geoms all have brackets!\nLet’s fill the violin plots, adding some transparency. We’ll also make the boxes on the boxplots a bit narrower so that we can see all the violin data, and let’s remove the outlier points.\n\niris %&gt;%\n  ggplot(\n    aes(\n      Species,\n      Petal.Length\n        )\n        )+\n  geom_violin(mapping = aes(fill=Species))+\n    geom_boxplot(width=0.1,outliers = F)\n\n\n\n\n\n\n\n\nFinally, let’s add the points, jittering them so that they don’t all line up along the midlines with geom_jitter.\n\niris %&gt;%\n  ggplot(\n    aes(\n      Species,\n      Petal.Length\n        )\n        )+\n  geom_violin(mapping = aes(fill=Species))+\n    geom_boxplot(width=0.1,outliers = F)+\n  geom_jitter(size=0.3,width = 0.2)\n\n\n\n\n\n\n\n\n\n\n\n1.9.9 Tile plots\ngeom_tile() – Creates heatmap-like visuals by filling rectangular areas based on values.\n-   Example: `geom_tile()`\nThis kind of heatmap is great for showing the value of a variable (defined with fill) in a grid representing several classes on x and y axis.\n\niris %&gt;%\n  ggplot(\n    aes(\n      Species,\n      Petal.Length&gt;3,\n      fill = Petal.Width\n        )\n        )+\ngeom_tile()\n\n\n\n\n\n\n\n\ngeom_jitter() – Adds small random noise to points, useful for avoiding overplotting.\n-   Example: `geom_jitter()`\ngeom_ribbon() – Fills the area between two y-values (usually a line and its confidence interval).\n-   Example: `geom_ribbon()`\ngeom_text() – Adds text annotations to points in the plot.\n-   Example: `geom_text(aes(label = ...))`\ngeom_errorbar() – Adds error bars to plots (e.g., for displaying variability or uncertainty).\n-   Example: `geom_errorbar()`\n\n\n1.9.10 Separate wider\n\ndf &lt;- tibble(id = 1:3, patient_id = c(\"m-123\", \"f-455\", \"f-123\"))\ndf\n\n# A tibble: 3 × 2\n     id patient_id\n  &lt;int&gt; &lt;chr&gt;     \n1     1 m-123     \n2     2 f-455     \n3     3 f-123     \n\n\nThere are three basic ways to split up a string into pieces\n\n1.9.10.1 With a delimiter\n\ndf %&gt;% \n  separate_wider_delim (\n    patient_id, \n    delim = \"-\", \n    names = c(\"gender\", \"unit\")\n    )\n\n# A tibble: 3 × 3\n     id gender unit \n  &lt;int&gt; &lt;chr&gt;  &lt;chr&gt;\n1     1 m      123  \n2     2 f      455  \n3     3 f      123  \n\n\n\n\n1.9.10.2 By string length\nHere you provide a set of widths to map new columns to various characters.\nThe example data are in the form m-123 where the m represents gender, the - is just a delimiter and the 123 is the participant ID.\nwe can assign characters with var = n where n is the width of the string in characters.\nwidths = c(gender = 1)\n\nwill assign the first character in the strong to a new variable gender.\n\nwidths = c(gender = 1, 1)\n\nAssigns the first character in the strong to a new variable gender.\nThe next character will be dropped\n\nwidths = c(gender = 1, 1, unit=3)\n\nAssigns the first character in the strong to a new variable gender.\nThe next character will be dropped\nFinally assigns the last 3 characters to a new variable unit\n\n\n\n1.9.10.3 Or by REGEX\nRegular expressions are a poweful language for string matching.\n\ndf %&gt;% \n  separate_wider_regex(\n    patient_id, c(gender = \".\", \".\", unit = \"\\\\d+\"))\n\n# A tibble: 3 × 3\n     id gender unit \n  &lt;int&gt; &lt;chr&gt;  &lt;chr&gt;\n1     1 m      123  \n2     2 f      455  \n3     3 f      123  \n\n\nA full example is like this\n\ndf %&gt;% \n  separate_wider_position (\n    cols = patient_id,\n    widths = c(gender = 1, 1, unit=3))\n\n# A tibble: 3 × 3\n     id gender unit \n  &lt;int&gt; &lt;chr&gt;  &lt;chr&gt;\n1     1 m      123  \n2     2 f      455  \n3     3 f      123  \n\n\n\n\n\n1.9.11 Unite\nUnite joins columns, or merges them.\n\ndf &lt;- expand_grid(x = c(\"a\", NA), y = c(\"b\", NA))\ndf\n\n# A tibble: 4 × 2\n  x     y    \n  &lt;chr&gt; &lt;chr&gt;\n1 a     b    \n2 a     &lt;NA&gt; \n3 &lt;NA&gt;  b    \n4 &lt;NA&gt;  &lt;NA&gt; \n\n\n\n1.9.11.1 Unite, dropping NAs\n\ndf %&gt;% \n  unite(\n    \"z\",\n    x:y,\n    na.rm = FALSE,\n    remove = FALSE)\n\n# A tibble: 4 × 3\n  z     x     y    \n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 a_b   a     b    \n2 a_NA  a     &lt;NA&gt; \n3 NA_b  &lt;NA&gt;  b    \n4 NA_NA &lt;NA&gt;  &lt;NA&gt; \n\n\n\n\n1.9.11.2 Unite, removing originals and shirt\n\ndf %&gt;% \n  unite(\n    \"z\",\n    x:y, \n    na.rm = TRUE,\n    remove = FALSE\n    )\n\n# A tibble: 4 × 3\n  z     x     y    \n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 \"a_b\" a     b    \n2 \"a\"   a     &lt;NA&gt; \n3 \"b\"   &lt;NA&gt;  b    \n4 \"\"    &lt;NA&gt;  &lt;NA&gt; \n\n\n\n\n\n1.9.12 Summary of Exclusive Helper Functions:\n\nConditional Operations: case_when(), if_else()\nRange Check: between()\nMissing Value Handling: coalesce(), is.na()\nCumulative Functions: cumsum(), cummean(), cumall(), cumany()\nRow-based Operations: lag(), lead(), nth(), row_number()\nSummarizing or Counting: n(), pmin(), pmax(), any(), all()\n\nThese helper functions are used specifically within verbs like mutate(), filter(), summarise(), arrange(), and others to perform specialized operations inside the context of a single table.\n\n\n1.9.13 Case_when\n\n\n1.9.14",
    "crumbs": [
      "R | RStudio",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of R</span>"
    ]
  },
  {
    "objectID": "Cox_PH.html",
    "href": "Cox_PH.html",
    "title": "11  Survival Analysis with Cox-PH",
    "section": "",
    "text": "11.1 Create dummy dataset\nYou would provide a real data set at this point. The data are basically a tibble/df in which you provide a list of times at which a case became either an event/failure or censored (lost-to-followup or end of study). The key variables are some kind of time to event variable and a status variable indicating whether the case is an event of censored at that time to event. Additional covariates to the model can be added at this stage (here age and sex are included).\n# Number of observations\nn &lt;- 400  \n\n# Create a dummy dataset with group-specific event probabilities\nset.seed(123)\ndummy_data &lt;- tibble(\n  time_to_event = rexp(n, rate = 0.1),  # Generate random survival times\n  sex = sample(c(\"Male\", \"Female\"), size = n, replace = TRUE),\n  age = rnorm(n, mean = 50, sd = 10),\n  status = ifelse(sex == \"Male\", \n                  rbinom(n, size = 1, prob = 0.8),  # Higher event probability for males\n                  rbinom(n, size = 1, prob = 0.4))  # Lower event probability for females\n)\n\n# Display the first 50 rows\nkable(dummy_data[1:50,])\n\n\n\n\ntime_to_event\nsex\nage\nstatus\n\n\n\n\n8.4345726\nFemale\n53.58856\n1\n\n\n5.7661027\nFemale\n43.91443\n1\n\n\n13.2905487\nFemale\n47.97759\n1\n\n\n0.3157736\nFemale\n47.26752\n0\n\n\n0.5621098\nMale\n45.31300\n0\n\n\n3.1650122\nFemale\n57.04167\n0\n\n\n3.1422729\nMale\n38.02636\n0\n\n\n1.4526680\nMale\n58.66366\n1\n\n\n27.2623646\nMale\n58.64152\n1\n\n\n0.2915345\nFemale\n38.01378\n0\n\n\n10.0483006\nMale\n56.39492\n1\n\n\n4.8021473\nFemale\n74.30227\n0\n\n\n2.8101363\nFemale\n44.42785\n0\n\n\n3.7711783\nMale\n58.44904\n1\n\n\n1.8828404\nFemale\n42.17798\n1\n\n\n8.4978613\nMale\n61.10711\n1\n\n\n15.6320354\nFemale\n52.49825\n0\n\n\n4.7876042\nMale\n66.51915\n0\n\n\n5.9093484\nMale\n35.41029\n1\n\n\n40.4101171\nFemale\n49.48702\n0\n\n\n8.4314973\nFemale\n44.73075\n1\n\n\n9.6587121\nFemale\n48.02735\n0\n\n\n14.8527579\nFemale\n43.70421\n0\n\n\n13.4804449\nFemale\n41.66156\n1\n\n\n11.6852898\nFemale\n55.78722\n1\n\n\n16.0585234\nFemale\n39.12419\n1\n\n\n14.9674287\nFemale\n64.84031\n0\n\n\n15.7065255\nMale\n38.13793\n1\n\n\n0.3176774\nMale\n51.01079\n1\n\n\n5.9784969\nMale\n55.32989\n0\n\n\n21.6783975\nFemale\n55.86735\n1\n\n\n5.0661573\nMale\n46.98253\n1\n\n\n2.5955782\nMale\n50.79502\n1\n\n\n25.9689212\nMale\n59.61264\n1\n\n\n12.2902573\nFemale\n35.43534\n1\n\n\n7.9068176\nFemale\n42.18260\n0\n\n\n6.2928008\nMale\n53.20402\n1\n\n\n12.5464100\nFemale\n45.55218\n0\n\n\n5.8868464\nMale\n63.70004\n1\n\n\n11.2929003\nFemale\n56.73254\n1\n\n\n4.2036480\nMale\n50.72167\n1\n\n\n72.1100758\nFemale\n34.92243\n1\n\n\n8.4572197\nFemale\n50.26100\n0\n\n\n2.2554201\nFemale\n46.83584\n1\n\n\n11.0033882\nMale\n48.97653\n0\n\n\n22.4830569\nMale\n38.18441\n1\n\n\n13.6373430\nFemale\n54.98658\n1\n\n\n5.7639167\nFemale\n39.61044\n0\n\n\n27.2527585\nFemale\n47.73778\n0\n\n\n13.1216304\nFemale\n53.81426\n1",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Survival Analysis with Cox-PH</span>"
    ]
  },
  {
    "objectID": "Cox_PH.html#fit-a-cox-proportional-hazards-cox-ph-model",
    "href": "Cox_PH.html#fit-a-cox-proportional-hazards-cox-ph-model",
    "title": "11  Survival Analysis with Cox-PH",
    "section": "11.2 Fit a Cox Proportional Hazards (Cox-PH) model",
    "text": "11.2 Fit a Cox Proportional Hazards (Cox-PH) model\nThe example below applies a Cox-PH model which tests whether survival is explained by age and sex.\n\n# Fit a Cox Proportional Hazards model\ncox_model &lt;- coxph(Surv(time_to_event, status) ~ age + sex, data = dummy_data)\n\n# Summary of the Cox PH model\nsummary(cox_model)\n\nCall:\ncoxph(formula = Surv(time_to_event, status) ~ age + sex, data = dummy_data)\n\n  n= 400, number of events= 241 \n\n             coef exp(coef)  se(coef)      z Pr(&gt;|z|)    \nage     -0.003303  0.996702  0.006417 -0.515    0.607    \nsexMale  0.802430  2.230955  0.140936  5.694 1.24e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n        exp(coef) exp(-coef) lower .95 upper .95\nage        0.9967     1.0033    0.9842     1.009\nsexMale    2.2310     0.4482    1.6925     2.941\n\nConcordance= 0.594  (se = 0.02 )\nLikelihood ratio test= 36.97  on 2 df,   p=9e-09\nWald test            = 34.31  on 2 df,   p=4e-08\nScore (logrank) test = 36.18  on 2 df,   p=1e-08\n\n\nexp(coef) is essentially an odds ratio similar to those in a logistic regression.\nIn this example, being male carries a proportional hazard of 1.04 (95% CI 0.76 - 1.22) compared to being female.\nIf you like P values, Pr(&gt;|z|) is exactly that.",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Survival Analysis with Cox-PH</span>"
    ]
  },
  {
    "objectID": "Cox_PH.html#plot-the-survival-curve-as-a-null-model-no-strata",
    "href": "Cox_PH.html#plot-the-survival-curve-as-a-null-model-no-strata",
    "title": "11  Survival Analysis with Cox-PH",
    "section": "11.3 Plot the survival curve as a null model (no strata)",
    "text": "11.3 Plot the survival curve as a null model (no strata)\n\nggsurvplot(survfit(cox_model), \n           data = dummy_data, \n           pval = TRUE,\n           risk.table = TRUE, \n           risk.table.title = \"Survival Table\",\n           surv.scale = \"percent\", # You can change this to other scales like \"probability\"\n           )",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Survival Analysis with Cox-PH</span>"
    ]
  },
  {
    "objectID": "Cox_PH.html#plot-the-survival-curves-strata",
    "href": "Cox_PH.html#plot-the-survival-curves-strata",
    "title": "11  Survival Analysis with Cox-PH",
    "section": "11.4 Plot the survival curve’s strata",
    "text": "11.4 Plot the survival curve’s strata\n\n# Plot separate survival curves for each sex without covariates\nggsurvplot(survfit(Surv(time_to_event, status) ~ sex, data = dummy_data), \n           data = dummy_data, pval = TRUE, \n           risk.table = TRUE, risk.table.title = \"Survival Table\",\n           surv.scale = \"percent\", # You can change this to other scales like \"probability\"\n           palette = c(\"blue\", \"red\"), # Colors for the curves\n           conf.int = TRUE, # Show confidence intervals\n           ggtheme = theme_minimal())",
    "crumbs": [
      "Statistics",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Survival Analysis with Cox-PH</span>"
    ]
  },
  {
    "objectID": "R_basics.html#joining",
    "href": "R_basics.html#joining",
    "title": "1  Basics of R",
    "section": "1.8 Joining",
    "text": "1.8 Joining\n\nleft_join() / right_join() / inner_join() / full_join():\\\n\nJoins add columns from one tibble to another, matching the observations using key variables.\nThere are three types of join\n\nA left_join() keeps all observations in x.\nA right_join() keeps all observations in y.\nA full_join() keeps all observations in x and y.\n\nWe’ll use the band_members and band_instruments data frames for this\n\nband_members\n\n# A tibble: 3 × 2\n  name  band   \n  &lt;chr&gt; &lt;chr&gt;  \n1 Mick  Stones \n2 John  Beatles\n3 Paul  Beatles\n\n\n\nband_instruments\n\n# A tibble: 3 × 2\n  name  plays \n  &lt;chr&gt; &lt;chr&gt; \n1 John  guitar\n2 Paul  bass  \n3 Keith guitar\n\n\nYou can see that both tibbles contain two variables, of which one is called name. This will be the key variable that is used for joining. R will automatically look for matching variables, and will merge the data semi-automatically. It even works if there’s more than one key variable.\n\n1.8.1 Left join\n\nband_members %&gt;% \nleft_join(\n  band_instruments\n)\n\nJoining with `by = join_by(name)`\n\n\n# A tibble: 3 × 3\n  name  band    plays \n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n1 Mick  Stones  &lt;NA&gt;  \n2 John  Beatles guitar\n3 Paul  Beatles bass  \n\n\nYou can see that the new left_joined tibble now contains three variables.\nAll three band members who were in the band_members tibble are still represented here, but Keith is not included in this tibble because left_join adds new columns to observations that already exist in band_members\n\n\n1.8.2 Right Join\nThe right_join works in exactly the opposite way. Here the right_join adds new columns to the observations of the right hand tibble (i.e. to band_instruments).\n\nright_join(\n  band_members,\n  band_instruments\n)\n\nJoining with `by = join_by(name)`\n\n\n# A tibble: 3 × 3\n  name  band    plays \n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n1 John  Beatles guitar\n2 Paul  Beatles bass  \n3 Keith &lt;NA&gt;    guitar\n\n\n\n\n1.8.3 Full Join\nThe full_join keeps all the observations and all the columns of both data sets.\n\nfull_join(\n  band_members,\n  band_instruments\n)\n\nJoining with `by = join_by(name)`\n\n\n# A tibble: 4 × 3\n  name  band    plays \n  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; \n1 Mick  Stones  &lt;NA&gt;  \n2 John  Beatles guitar\n3 Paul  Beatles bass  \n4 Keith &lt;NA&gt;    guitar",
    "crumbs": [
      "R | RStudio",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Basics of R</span>"
    ]
  },
  {
    "objectID": "diva_gis.html",
    "href": "diva_gis.html",
    "title": "24  GIS Data to ODK itemlist",
    "section": "",
    "text": "24.1 Background\nUsing Administrative data from [DIVA-GIS](www.diva-gis.org), this script will convert the geographical administrative data (levels 0-3) for one or more country and output an itemsets.csv file that works with ODK and preserves accented characters (tested only on roman characters). The primary purpose here is to create a list that is compatible with the cascading select system that ODK uses to filter down to more granular responses in questions where you’d want to capture district &gt; area &gt; village or similar.\nThis also removes accents from internal variables like the XLSForm ‘name’ column.\nAccents will appear on screen, but won’t be preserved in data frames. This is desirable because working with mixed data that may or may not include accents is a pain.",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>GIS Data to ODK itemlist</span>"
    ]
  },
  {
    "objectID": "diva_gis.html#data",
    "href": "diva_gis.html#data",
    "title": "24  GIS Data to ODK itemlist",
    "section": "24.2 Data",
    "text": "24.2 Data\nYou will need to get administrative data from [DIVA GIS](http://www.diva-gis.org/datadown#) for each of the countries you want to include.\nUnzip this data to a folder in the same directory as this script,\nThis example uses Uganda and Democratic Republic of Congo.",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>GIS Data to ODK itemlist</span>"
    ]
  },
  {
    "objectID": "diva_gis.html#libraries",
    "href": "diva_gis.html#libraries",
    "title": "24  GIS Data to ODK itemlist",
    "section": "24.3 Libraries",
    "text": "24.3 Libraries\n\nlibrary(knitr)\n\n\n24.3.1 Create a folder to house data\n\nif(!dir.exists(\"data/divadownload/\")){dir.create(\"data/divadownload\")}\nsystem(\"rm -rf data/divadownload/*\")\n\n\n\n24.3.2 Define target countries\nSpecify ISO codes (3 digit) to tell R which data sets to include. A full list of ISO codes is available [here](#https://en.wikipedia.org/wiki/ISO_3166-1_alpha-3 )\n\ncountries&lt;-c(\"UGA\",\"COD\")",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>GIS Data to ODK itemlist</span>"
    ]
  },
  {
    "objectID": "diva_gis.html#download-and-bind-data",
    "href": "diva_gis.html#download-and-bind-data",
    "title": "24  GIS Data to ODK itemlist",
    "section": "24.4 Download and bind data",
    "text": "24.4 Download and bind data\nFor each country, find the data set in the folder structure and load up then bind together\n\noptions(timeout=120)\nfor(i in 1:length(countries))\n{\n  \n  #download the data set for country i\n  download.file(url = paste(\"http://biogeo.ucdavis.edu/data/diva/adm/\",countries[i],\"_adm.zip\",sep=\"\"),destfile =paste(\"data/divadownload/\",countries[i],\"_adm.zip\",sep=\"\"))\n\n  #unzip the data for country i\n  system (paste(\"unzip data/divadownload/\",countries[i],\"_adm.zip -d data/divadownload/\",countries[i],sep=\"\"))\n  \n  #read the level 3 data for country i\n  level3data&lt;-read.csv(list.files(pattern = paste(countries[i],\"_adm3.csv\",sep=\"\"),full.names = T,recursive = T))\n  #select only the relevant columns\n  level3data&lt;-level3data[,c(\"NAME_0\",\"NAME_1\",\"NAME_2\",\"NAME_3\",\"ISO\")]\n  \n  #for the first country, create a new df\n  if(i==1){full.data.output&lt;-level3data}\n  #for countries 2 to n, bind data\n  if(i!=1){full.data.output&lt;-rbind(full.data.output,level3data)}\n}",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>GIS Data to ODK itemlist</span>"
    ]
  },
  {
    "objectID": "diva_gis.html#define-function-to-remove-accents",
    "href": "diva_gis.html#define-function-to-remove-accents",
    "title": "24  GIS Data to ODK itemlist",
    "section": "24.5 Define function to remove accents",
    "text": "24.5 Define function to remove accents\n\n#define function to remove accents from text\nremoveAccents&lt;-function(x)\n{\n  a &lt;- c('À', 'Á', 'Â', 'Ã', 'Ä', 'Å', 'Æ', 'Ç', 'È', 'É', 'Ê', 'Ë', 'Ì', 'Í', 'Î', 'Ï', 'Ð', 'Ñ', 'Ò', 'Ó', 'Ô', 'Õ', 'Ö', 'Ø', 'Ù', 'Ú', 'Û', 'Ü', 'Ý', 'ß', 'à', 'á', 'â', 'ã', 'ä', 'å', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'ì', 'í', 'î', 'ï', 'ñ', 'ò', 'ó', 'ô', 'õ', 'ö', 'ø', 'ù', 'ú', 'û', 'ü', 'ý', 'ÿ', 'Ā', 'ā', 'Ă', 'ă', 'Ą', 'ą', 'Ć', 'ć', 'Ĉ', 'ĉ', 'Ċ', 'ċ', 'Č', 'č', 'Ď', 'ď', 'Đ', 'đ', 'Ē', 'ē', 'Ĕ', 'ĕ', 'Ė', 'ė', 'Ę', 'ę', 'Ě', 'ě', 'Ĝ', 'ĝ', 'Ğ', 'ğ', 'Ġ', 'ġ', 'Ģ', 'ģ', 'Ĥ', 'ĥ', 'Ħ', 'ħ', 'Ĩ', 'ĩ', 'Ī', 'ī', 'Ĭ', 'ĭ', 'Į', 'į', 'İ', 'ı', 'Ĳ', 'ĳ', 'Ĵ', 'ĵ', 'Ķ', 'ķ', 'Ĺ', 'ĺ', 'Ļ', 'ļ', 'Ľ', 'ľ', 'Ŀ', 'ŀ', 'Ł', 'ł', 'Ń', 'ń', 'Ņ', 'ņ', 'Ň', 'ň', 'ŉ', 'Ō', 'ō', 'Ŏ', 'ŏ', 'Ő', 'ő', 'Œ', 'œ', 'Ŕ', 'ŕ', 'Ŗ', 'ŗ', 'Ř', 'ř', 'Ś', 'ś', 'Ŝ', 'ŝ', 'Ş', 'ş', 'Š', 'š', 'Ţ', 'ţ', 'Ť', 'ť', 'Ŧ', 'ŧ', 'Ũ', 'ũ', 'Ū', 'ū', 'Ŭ', 'ŭ', 'Ů', 'ů', 'Ű', 'ű', 'Ų', 'ų', 'Ŵ', 'ŵ', 'Ŷ', 'ŷ', 'Ÿ', 'Ź', 'ź', 'Ż', 'ż', 'Ž', 'ž', 'ſ', 'ƒ', 'Ơ', 'ơ', 'Ư', 'ư', 'Ǎ', 'ǎ', 'Ǐ', 'ǐ', 'Ǒ', 'ǒ', 'Ǔ', 'ǔ', 'Ǖ', 'ǖ', 'Ǘ', 'ǘ', 'Ǚ', 'ǚ', 'Ǜ', 'ǜ', 'Ǻ', 'ǻ', 'Ǽ', 'ǽ', 'Ǿ', 'ǿ');\n  b &lt;- c('A', 'A', 'A', 'A', 'A', 'A', 'AE', 'C', 'E', 'E', 'E', 'E', 'I', 'I', 'I', 'I', 'D', 'N', 'O', 'O', 'O', 'O', 'O', 'O', 'U', 'U', 'U', 'U', 'Y', 's', 'a', 'a', 'a', 'a', 'a', 'a', 'ae', 'c', 'e', 'e', 'e', 'e', 'i', 'i', 'i', 'i', 'n', 'o', 'o', 'o', 'o', 'o', 'o', 'u', 'u', 'u', 'u', 'y', 'y', 'A', 'a', 'A', 'a', 'A', 'a', 'C', 'c', 'C', 'c', 'C', 'c', 'C', 'c', 'D', 'd', 'D', 'd', 'E', 'e', 'E', 'e', 'E', 'e', 'E', 'e', 'E', 'e', 'G', 'g', 'G', 'g', 'G', 'g', 'G', 'g', 'H', 'h', 'H', 'h', 'I', 'i', 'I', 'i', 'I', 'i', 'I', 'i', 'I', 'i', 'IJ', 'ij', 'J', 'j', 'K', 'k', 'L', 'l', 'L', 'l', 'L', 'l', 'L', 'l', 'l', 'l', 'N', 'n', 'N', 'n', 'N', 'n', 'n', 'O', 'o', 'O', 'o', 'O', 'o', 'OE', 'oe', 'R', 'r', 'R', 'r', 'R', 'r', 'S', 's', 'S', 's', 'S', 's', 'S', 's', 'T', 't', 'T', 't', 'T', 't', 'U', 'u', 'U', 'u', 'U', 'u', 'U', 'u', 'U', 'u', 'U', 'u', 'W', 'w', 'Y', 'y', 'Y', 'Z', 'z', 'Z', 'z', 'Z', 'z', 's', 'f', 'O', 'o', 'U', 'u', 'A', 'a', 'I', 'i', 'O', 'o', 'U', 'u', 'U', 'u', 'U', 'u', 'U', 'u', 'U', 'u', 'A', 'a', 'AE', 'ae', 'O', 'o');\n  for(i in 1:length(a))\n  {\n    x&lt;-gsub(x = x,pattern = a[i],replacement = b[i])\n  }\n  return(x)\n}",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>GIS Data to ODK itemlist</span>"
    ]
  },
  {
    "objectID": "diva_gis.html#tidy-data",
    "href": "diva_gis.html#tidy-data",
    "title": "24  GIS Data to ODK itemlist",
    "section": "24.6 Tidy data",
    "text": "24.6 Tidy data\n\n#Set correct names so that label is descriptive country name\nnames(full.data.output)[which(names(full.data.output)==\"NAME_0\")]&lt;-\"label\"\n#set correct names so that ISO code is NAME_0 (level 0 country data)\nnames(full.data.output)[which(names(full.data.output)==\"ISO\")]&lt;-\"NAME_0\"\n\n\n#get rid of whitespace and dots and so on [might need to add more]\nfull.data.output&lt;-full.data.output[,c(\"NAME_0\",\"NAME_1\",\"NAME_2\",\"NAME_3\",\"label\")]\nfull.data.output$NAME_1&lt;-gsub(full.data.output$NAME_1,pattern = \"/| |'|//.\",replacement = \"_\")\nfull.data.output$NAME_2&lt;-gsub(full.data.output$NAME_2,pattern = \"/| |'|//.\",replacement = \"_\")\nfull.data.output$NAME_3&lt;-gsub(full.data.output$NAME_3,pattern = \"/| |'|//.\",replacement = \"_\")\n\n#find level zero and blank out levels 1,2,3\nlevel0&lt;-full.data.output\nlevel0[,2:4]&lt;-\"\"\nlevel0&lt;-unique(level0)\nlevel0$list_name&lt;-\"NAME_0\"\n\n\n#find level one and blank out levels 2,3\nlevel1&lt;-full.data.output[,c(2,1,3,4,5)]\nlevel1[,3:4]&lt;-\"\"\nlevel1&lt;-unique(level1)\nlevel1$list_name&lt;-\"NAME_1\"\nlevel1$label&lt;-level1$NAME_1\nx&lt;-level1\nx$NAME_1&lt;-\"\"\nx$label&lt;-\"\"\nx&lt;-unique(x)\nx$NAME_1&lt;-\"Other\"\nx$label&lt;-\"Other\"\nlevel1&lt;-rbind(level1,x)\nrm(x)\n\n\n#find level two and blank out level 3\nlevel2&lt;-full.data.output[,c(3,1,2,4,5)]\nlevel2[,4]&lt;-\"\"\nlevel2&lt;-unique(level2)\nlevel2$list_name&lt;-\"NAME_2\"\nlevel2$label&lt;-level2$NAME_2\nx&lt;-level2\nx$NAME_2&lt;-\"\"\nx$label&lt;-\"\"\nx&lt;-unique(x)\nx$NAME_2&lt;-\"Other\"\nx$label&lt;-\"Other\"\nlevel2&lt;-rbind(level2,x)\nrm(x)\n\n#find level three\nlevel3&lt;-full.data.output[,c(4,1,2,3,5)]\nlevel3&lt;-unique(level3)\nlevel3$list_name&lt;-\"NAME_3\"\nlevel3$label&lt;-level3$NAME_3\nx&lt;-level3\nx$NAME_3&lt;-\"\"\nx$label&lt;-\"\"\nx&lt;-unique(x)\nx$NAME_3&lt;-\"Other\"\nx$label&lt;-\"Other\"\nlevel3&lt;-rbind(level3,x)\nrm(x)\n\n\n#put it all together\noutput&lt;-level0\noutput&lt;-rbind(output,level1)\noutput&lt;-rbind(output,level2)\noutput&lt;-rbind(output,level3)\n\n\n# remove accents from name, levels 0-3, leaving them only in label.\noutput&lt;-output[,c(\"list_name\",\"NAME_0\",\"NAME_1\",\"NAME_2\",\"NAME_3\",\"label\")]\noutput$name&lt;-output$label\noutput$name&lt;-removeAccents(output$name)\noutput$NAME_0&lt;-removeAccents(output$NAME_0)\noutput$NAME_1&lt;-removeAccents(output$NAME_1)\noutput$NAME_2&lt;-removeAccents(output$NAME_2)\noutput$NAME_3&lt;-removeAccents(output$NAME_3)",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>GIS Data to ODK itemlist</span>"
    ]
  },
  {
    "objectID": "diva_gis.html#show-output",
    "href": "diva_gis.html#show-output",
    "title": "24  GIS Data to ODK itemlist",
    "section": "24.7 Show output",
    "text": "24.7 Show output\n\nkable(head(output,100))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlist_name\nNAME_0\nNAME_1\nNAME_2\nNAME_3\nlabel\nname\n\n\n\n\n1\nNAME_0\nUGA\n\n\n\nUganda\nUganda\n\n\n968\nNAME_0\nCOD\n\n\n\nDemocratic Republic of the Congo\nDemocratic Republic of the Congo\n\n\n12\nNAME_1\nUGA\nAdjumani\n\n\nAdjumani\nAdjumani\n\n\n7\nNAME_1\nUGA\nApac\n\n\nApac\nApac\n\n\n29\nNAME_1\nUGA\nArua\n\n\nArua\nArua\n\n\n65\nNAME_1\nUGA\nBugiri\n\n\nBugiri\nBugiri\n\n\n82\nNAME_1\nUGA\nBundibugyo\n\n\nBundibugyo\nBundibugyo\n\n\n92\nNAME_1\nUGA\nBushenyi\n\n\nBushenyi\nBushenyi\n\n\n122\nNAME_1\nUGA\nBusia\n\n\nBusia\nBusia\n\n\n132\nNAME_1\nUGA\nGulu\n\n\nGulu\nGulu\n\n\n155\nNAME_1\nUGA\nHoima\n\n\nHoima\nHoima\n\n\n169\nNAME_1\nUGA\nIganga\n\n\nIganga\nIganga\n\n\n194\nNAME_1\nUGA\nJinja\n\n\nJinja\nJinja\n\n\n205\nNAME_1\nUGA\nKabale\n\n\nKabale\nKabale\n\n\n224\nNAME_1\nUGA\nKabarole\n\n\nKabarole\nKabarole\n\n\n239\nNAME_1\nUGA\nKaberamaido\n\n\nKaberamaido\nKaberamaido\n\n\n248\nNAME_1\nUGA\nKalangala\n\n\nKalangala\nKalangala\n\n\n255\nNAME_1\nUGA\nKampala\n\n\nKampala\nKampala\n\n\n260\nNAME_1\nUGA\nKamuli\n\n\nKamuli\nKamuli\n\n\n283\nNAME_1\nUGA\nKamwenge\n\n\nKamwenge\nKamwenge\n\n\n292\nNAME_1\nUGA\nKanungu\n\n\nKanungu\nKanungu\n\n\n302\nNAME_1\nUGA\nKapchorwa\n\n\nKapchorwa\nKapchorwa\n\n\n318\nNAME_1\nUGA\nKasese\n\n\nKasese\nKasese\n\n\n340\nNAME_1\nUGA\nKatakwi\n\n\nKatakwi\nKatakwi\n\n\n358\nNAME_1\nUGA\nKayunga\n\n\nKayunga\nKayunga\n\n\n367\nNAME_1\nUGA\nKibale\n\n\nKibale\nKibale\n\n\n386\nNAME_1\nUGA\nKiboga\n\n\nKiboga\nKiboga\n\n\n400\nNAME_1\nUGA\nKisoro\n\n\nKisoro\nKisoro\n\n\n414\nNAME_1\nUGA\nKitgum\n\n\nKitgum\nKitgum\n\n\n433\nNAME_1\nUGA\nKotido\n\n\nKotido\nKotido\n\n\n453\nNAME_1\nUGA\nKumi\n\n\nKumi\nKumi\n\n\n469\nNAME_1\nUGA\nKyenjojo\n\n\nKyenjojo\nKyenjojo\n\n\n483\nNAME_1\nUGA\nLake_Albert\n\n\nLake_Albert\nLake_Albert\n\n\n484\nNAME_1\nUGA\nLake_Victoria\n\n\nLake_Victoria\nLake_Victoria\n\n\n485\nNAME_1\nUGA\nLira\n\n\nLira\nLira\n\n\n513\nNAME_1\nUGA\nLuwero\n\n\nLuwero\nLuwero\n\n\n533\nNAME_1\nUGA\nMasaka\n\n\nMasaka\nMasaka\n\n\n556\nNAME_1\nUGA\nMasindi\n\n\nMasindi\nMasindi\n\n\n570\nNAME_1\nUGA\nMayuge\n\n\nMayuge\nMayuge\n\n\n577\nNAME_1\nUGA\nMbale\n\n\nMbale\nMbale\n\n\n608\nNAME_1\nUGA\nMbarara\n\n\nMbarara\nMbarara\n\n\n654\nNAME_1\nUGA\nMoroto\n\n\nMoroto\nMoroto\n\n\n665\nNAME_1\nUGA\nMoyo\n\n\nMoyo\nMoyo\n\n\n673\nNAME_1\nUGA\nMpigi\n\n\nMpigi\nMpigi\n\n\n690\nNAME_1\nUGA\nMubende\n\n\nMubende\nMubende\n\n\n710\nNAME_1\nUGA\nMukono\n\n\nMukono\nMukono\n\n\n738\nNAME_1\nUGA\nNakapiripirit\n\n\nNakapiripirit\nNakapiripirit\n\n\n748\nNAME_1\nUGA\nNakasongola\n\n\nNakasongola\nNakasongola\n\n\n757\nNAME_1\nUGA\nNebbi\n\n\nNebbi\nNebbi\n\n\n776\nNAME_1\nUGA\nNtungamo\n\n\nNtungamo\nNtungamo\n\n\n791\nNAME_1\nUGA\nPader\n\n\nPader\nPader\n\n\n809\nNAME_1\nUGA\nPallisa\n\n\nPallisa\nPallisa\n\n\n837\nNAME_1\nUGA\nRakai\n\n\nRakai\nRakai\n\n\n864\nNAME_1\nUGA\nRukungiri\n\n\nRukungiri\nRukungiri\n\n\n875\nNAME_1\nUGA\nSembabule\n\n\nSembabule\nSembabule\n\n\n882\nNAME_1\nUGA\nSironko\n\n\nSironko\nSironko\n\n\n902\nNAME_1\nUGA\nSoroti\n\n\nSoroti\nSoroti\n\n\n919\nNAME_1\nUGA\nTororo\n\n\nTororo\nTororo\n\n\n943\nNAME_1\nUGA\nWakiso\n\n\nWakiso\nWakiso\n\n\n960\nNAME_1\nUGA\nYumbe\n\n\nYumbe\nYumbe\n\n\n9682\nNAME_1\nCOD\nEquateur\n\n\nÉquateur\nEquateur\n\n\n993\nNAME_1\nCOD\nBandundu\n\n\nBandundu\nBandundu\n\n\n1010\nNAME_1\nCOD\nBas-Congo\n\n\nBas-Congo\nBas-Congo\n\n\n1022\nNAME_1\nCOD\nKasai-Occidental\n\n\nKasaï-Occidental\nKasai-Occidental\n\n\n1033\nNAME_1\nCOD\nKasai-Oriental\n\n\nKasaï-Oriental\nKasai-Oriental\n\n\n1046\nNAME_1\nCOD\nKatanga\n\n\nKatanga\nKatanga\n\n\n1069\nNAME_1\nCOD\nKinshasa_City\n\n\nKinshasa_City\nKinshasa_City\n\n\n1071\nNAME_1\nCOD\nKivu\n\n\nKivu\nKivu\n\n\n1093\nNAME_1\nCOD\nOrientale\n\n\nOrientale\nOrientale\n\n\n11\nNAME_1\nUGA\nOther\n\n\nOther\nOther\n\n\n9681\nNAME_1\nCOD\nOther\n\n\nOther\nOther\n\n\n13\nNAME_2\nUGA\nAdjumani\nEast_Moyo\n\nEast_Moyo\nEast_Moyo\n\n\n72\nNAME_2\nUGA\nApac\nKole\n\nKole\nKole\n\n\n121\nNAME_2\nUGA\nApac\nKwania\n\nKwania\nKwania\n\n\n17\nNAME_2\nUGA\nApac\nMaruzi\n\nMaruzi\nMaruzi\n\n\n22\nNAME_2\nUGA\nApac\nOyam\n\nOyam\nOyam\n\n\n293\nNAME_2\nUGA\nArua\nArua_Municipality\n\nArua_Municipality\nArua_Municipality\n\n\n31\nNAME_2\nUGA\nArua\nAyivu\n\nAyivu\nAyivu\n\n\n37\nNAME_2\nUGA\nArua\nKoboko\n\nKoboko\nKoboko\n\n\n42\nNAME_2\nUGA\nArua\nMadi-Okollo\n\nMadi-Okollo\nMadi-Okollo\n\n\n48\nNAME_2\nUGA\nArua\nMaracha\n\nMaracha\nMaracha\n\n\n55\nNAME_2\nUGA\nArua\nTerego\n\nTerego\nTerego\n\n\n61\nNAME_2\nUGA\nArua\nVurra\n\nVurra\nVurra\n\n\n652\nNAME_2\nUGA\nBugiri\nBukooli\n\nBukooli\nBukooli\n\n\n823\nNAME_2\nUGA\nBundibugyo\nBwamba\n\nBwamba\nBwamba\n\n\n89\nNAME_2\nUGA\nBundibugyo\nNtoroko\n\nNtoroko\nNtoroko\n\n\n922\nNAME_2\nUGA\nBushenyi\nBuhweju\n\nBuhweju\nBuhweju\n\n\n96\nNAME_2\nUGA\nBushenyi\nBunyaruguru\n\nBunyaruguru\nBunyaruguru\n\n\n101\nNAME_2\nUGA\nBushenyi\nIgara\n\nIgara\nIgara\n\n\n108\nNAME_2\nUGA\nBushenyi\nRuhinda\n\nRuhinda\nRuhinda\n\n\n115\nNAME_2\nUGA\nBushenyi\nSheema\n\nSheema\nSheema\n\n\n1222\nNAME_2\nUGA\nBusia\nSamia-Bugwe\n\nSamia-Bugwe\nSamia-Bugwe\n\n\n1322\nNAME_2\nUGA\nGulu\nAswa\n\nAswa\nAswa\n\n\n137\nNAME_2\nUGA\nGulu\nGulu\n\nGulu\nGulu\n\n\n141\nNAME_2\nUGA\nGulu\nKilak\n\nKilak\nKilak\n\n\n145\nNAME_2\nUGA\nGulu\nNwoya\n\nNwoya\nNwoya\n\n\n149\nNAME_2\nUGA\nGulu\nOmoro\n\nOmoro\nOmoro\n\n\n1552\nNAME_2\nUGA\nHoima\nBugahya\n\nBugahya\nBugahya\n\n\n164\nNAME_2\nUGA\nHoima\nBuhaguzi\n\nBuhaguzi\nBuhaguzi\n\n\n1692\nNAME_2\nUGA\nIganga\nBugweri\n\nBugweri\nBugweri",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>GIS Data to ODK itemlist</span>"
    ]
  },
  {
    "objectID": "diva_gis.html#write-output-to-itemsets.csv",
    "href": "diva_gis.html#write-output-to-itemsets.csv",
    "title": "24  GIS Data to ODK itemlist",
    "section": "24.8 Write output to itemsets.csv",
    "text": "24.8 Write output to itemsets.csv\n\nwrite.csv(x = output,file = \"output/diva_itemsets.csv\",quote = F,row.names = F)",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>GIS Data to ODK itemlist</span>"
    ]
  },
  {
    "objectID": "diva_gis.html#delete-the-raw-data",
    "href": "diva_gis.html#delete-the-raw-data",
    "title": "24  GIS Data to ODK itemlist",
    "section": "24.9 Delete the raw data",
    "text": "24.9 Delete the raw data\n\nsystem(\"rm -rf data/divadownload/\")",
    "crumbs": [
      "ODK",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>GIS Data to ODK itemlist</span>"
    ]
  }
]